{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas\n!pip install torch\n!pip install nltk\n!pip install tqdm\n!pip install seaborn\n!pip install numpy\n!pip install sklearn","metadata":{"id":"Y0fOWhqwW-AT","outputId":"41f40fd4-ebae-43e8-fd1c-41db3fb72471","execution":{"iopub.status.busy":"2021-12-21T11:37:01.930422Z","iopub.execute_input":"2021-12-21T11:37:01.931307Z","iopub.status.idle":"2021-12-21T11:37:53.613494Z","shell.execute_reply.started":"2021-12-21T11:37:01.931164Z","shell.execute_reply":"2021-12-21T11:37:53.612645Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"id":"u3wugeOHW-AV","outputId":"7979e6ad-bff3-4493-c0e7-a9666383f9ae","execution":{"iopub.status.busy":"2021-12-21T11:37:53.616515Z","iopub.execute_input":"2021-12-21T11:37:53.616821Z","iopub.status.idle":"2021-12-21T11:37:54.781197Z","shell.execute_reply.started":"2021-12-21T11:37:53.616783Z","shell.execute_reply":"2021-12-21T11:37:54.780454Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Скачиваем данные","metadata":{"id":"m9XIrxSmW-AX"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv","metadata":{"id":"ep1FB3IBW-AY","outputId":"ed833b2b-3b1a-492a-d9a3-ad845a9074c0","execution":{"iopub.status.busy":"2021-12-21T11:37:54.782685Z","iopub.execute_input":"2021-12-21T11:37:54.783185Z","iopub.status.idle":"2021-12-21T11:37:57.012464Z","shell.execute_reply.started":"2021-12-21T11:37:54.783144Z","shell.execute_reply":"2021-12-21T11:37:57.011628Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# если ругается на то, что нет wget\n# !apt-get install wget","metadata":{"id":"BWA7IClKW-Aa","execution":{"iopub.status.busy":"2021-12-21T11:37:57.015503Z","iopub.execute_input":"2021-12-21T11:37:57.015820Z","iopub.status.idle":"2021-12-21T11:37:57.019886Z","shell.execute_reply.started":"2021-12-21T11:37:57.015779Z","shell.execute_reply":"2021-12-21T11:37:57.018841Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"id":"qJpFTPpsW-Ac","outputId":"614d0244-d82c-43fd-c756-c33a3383fa30","execution":{"iopub.status.busy":"2021-12-21T11:37:57.021367Z","iopub.execute_input":"2021-12-21T11:37:57.021627Z","iopub.status.idle":"2021-12-21T11:37:57.689219Z","shell.execute_reply.started":"2021-12-21T11:37:57.021589Z","shell.execute_reply":"2021-12-21T11:37:57.688347Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"qmzaEwy9W-Ae","execution":{"iopub.status.busy":"2021-12-21T11:37:57.691908Z","iopub.execute_input":"2021-12-21T11:37:57.692521Z","iopub.status.idle":"2021-12-21T11:37:57.697277Z","shell.execute_reply.started":"2021-12-21T11:37:57.692484Z","shell.execute_reply":"2021-12-21T11:37:57.696407Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('answers_subsample.csv')","metadata":{"id":"BbDKxq4EW-Ag","execution":{"iopub.status.busy":"2021-12-21T11:37:57.699101Z","iopub.execute_input":"2021-12-21T11:37:57.699711Z","iopub.status.idle":"2021-12-21T11:37:58.345820Z","shell.execute_reply.started":"2021-12-21T11:37:57.699646Z","shell.execute_reply":"2021-12-21T11:37:58.345050Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"hcAdsbS7W-Ai","outputId":"fe4de523-6803-40cd-ea40-a993217c57d3","execution":{"iopub.status.busy":"2021-12-21T11:37:58.347012Z","iopub.execute_input":"2021-12-21T11:37:58.347271Z","iopub.status.idle":"2021-12-21T11:37:58.364564Z","shell.execute_reply.started":"2021-12-21T11:37:58.347237Z","shell.execute_reply":"2021-12-21T11:37:58.363795Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data.category.value_counts() * 100 / data.shape[0]","metadata":{"id":"90tXLjfsW-Aj","outputId":"5a41f708-1102-49c7-a38f-795783ccdd81","execution":{"iopub.status.busy":"2021-12-21T11:37:58.365878Z","iopub.execute_input":"2021-12-21T11:37:58.366196Z","iopub.status.idle":"2021-12-21T11:37:58.399499Z","shell.execute_reply.started":"2021-12-21T11:37:58.366157Z","shell.execute_reply":"2021-12-21T11:37:58.398560Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Предобученные эмбеддинги\n[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \nВы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \nНиже мы сначала скачиваем, а потом распоковываем эмбеддинги.","metadata":{"id":"gfHbifWIW-Al"}},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n!gzip -d cc.ru.300.vec.gz","metadata":{"id":"PVhCzM3LW-Al","outputId":"7b800ec8-bcad-4859-f110-2ac5ddb07f0e","execution":{"iopub.status.busy":"2021-12-21T11:37:58.403347Z","iopub.execute_input":"2021-12-21T11:37:58.403743Z","iopub.status.idle":"2021-12-21T11:39:40.098231Z","shell.execute_reply.started":"2021-12-21T11:37:58.403693Z","shell.execute_reply":"2021-12-21T11:39:40.097399Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"id":"eJcT1qPZW-An","outputId":"6464b2a1-a04f-4112-a39d-4165ff7c4a79","execution":{"iopub.status.busy":"2021-12-21T11:39:40.099927Z","iopub.execute_input":"2021-12-21T11:39:40.100510Z","iopub.status.idle":"2021-12-21T11:39:40.768693Z","shell.execute_reply.started":"2021-12-21T11:39:40.100464Z","shell.execute_reply":"2021-12-21T11:39:40.767724Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize, wordpunct_tokenize\nfrom tqdm import tqdm","metadata":{"id":"M0lwyZUFW-Ap","execution":{"iopub.status.busy":"2021-12-21T11:39:40.772053Z","iopub.execute_input":"2021-12-21T11:39:40.772298Z","iopub.status.idle":"2021-12-21T11:39:40.776326Z","shell.execute_reply.started":"2021-12-21T11:39:40.772266Z","shell.execute_reply":"2021-12-21T11:39:40.775478Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# потом можете добавить свою предобработку\n\ndef process_text(text):\n    \n    words = wordpunct_tokenize(text.lower())\n    \n    return words","metadata":{"id":"QQpX51Y4W-Aq","execution":{"iopub.status.busy":"2021-12-21T11:39:40.777969Z","iopub.execute_input":"2021-12-21T11:39:40.778514Z","iopub.status.idle":"2021-12-21T11:39:40.787485Z","shell.execute_reply.started":"2021-12-21T11:39:40.778476Z","shell.execute_reply":"2021-12-21T11:39:40.786722Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"word2freq = {}\nlengths = []\n\nfor text in tqdm(data.text):\n    \n    words = process_text(text)\n    \n    lengths.append(len(words))\n    \n    for word in words:\n        \n        if word in word2freq:\n            word2freq[word] += 1\n        else:\n            word2freq[word] = 1","metadata":{"id":"HyI2erCDW-Ar","outputId":"0e1fe01d-03f8-4073-b646-53f1a0834d90","execution":{"iopub.status.busy":"2021-12-21T11:39:40.789627Z","iopub.execute_input":"2021-12-21T11:39:40.790145Z","iopub.status.idle":"2021-12-21T11:39:43.857218Z","shell.execute_reply.started":"2021-12-21T11:39:40.790107Z","shell.execute_reply":"2021-12-21T11:39:43.856542Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt","metadata":{"id":"FGzDm0ptW-At","execution":{"iopub.status.busy":"2021-12-21T11:39:43.858432Z","iopub.execute_input":"2021-12-21T11:39:43.858885Z","iopub.status.idle":"2021-12-21T11:39:43.934334Z","shell.execute_reply.started":"2021-12-21T11:39:43.858834Z","shell.execute_reply":"2021-12-21T11:39:43.933650Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nplt.title('Распределение длин слов в текстах')\nplt.xlabel('Длина предложения')\nplt.ylabel('Доля')\nsns.distplot(lengths)","metadata":{"id":"iZBR-aYDW-Av","outputId":"940b9a8b-91a9-4cdb-f79e-bcd0016e6958","execution":{"iopub.status.busy":"2021-12-21T11:39:43.935451Z","iopub.execute_input":"2021-12-21T11:39:43.936275Z","iopub.status.idle":"2021-12-21T11:39:45.134564Z","shell.execute_reply.started":"2021-12-21T11:39:43.936231Z","shell.execute_reply":"2021-12-21T11:39:45.133861Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"upper_threshold = 32\nlower_threshold = 3\n\ncorrect_percent = len([sent_len for sent_len in lengths \n                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n\n'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)","metadata":{"id":"OBzmPqXIW-Aw","outputId":"e4430b5f-2d2a-4ac9-fc1a-fa194edd7645","execution":{"iopub.status.busy":"2021-12-21T11:39:45.135818Z","iopub.execute_input":"2021-12-21T11:39:45.136158Z","iopub.status.idle":"2021-12-21T11:39:45.168687Z","shell.execute_reply.started":"2021-12-21T11:39:45.136118Z","shell.execute_reply":"2021-12-21T11:39:45.168060Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"len(word2freq)","metadata":{"id":"GbSer_0bW-Ay","outputId":"d71619df-f68b-42a8-d851-3c909ceb6370","execution":{"iopub.status.busy":"2021-12-21T11:39:45.169809Z","iopub.execute_input":"2021-12-21T11:39:45.170124Z","iopub.status.idle":"2021-12-21T11:39:45.178176Z","shell.execute_reply.started":"2021-12-21T11:39:45.170088Z","shell.execute_reply":"2021-12-21T11:39:45.177474Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))","metadata":{"id":"szg6XD3EW-Az","outputId":"f41121aa-cbb5-426b-b7bb-8f21b1822bd0","execution":{"iopub.status.busy":"2021-12-21T11:39:45.179406Z","iopub.execute_input":"2021-12-21T11:39:45.180042Z","iopub.status.idle":"2021-12-21T11:39:45.220238Z","shell.execute_reply.started":"2021-12-21T11:39:45.180004Z","shell.execute_reply":"2021-12-21T11:39:45.219552Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Читаем файл с эмбеддингами\n### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\nПоэтому прочитаем только те слова, которые мы знаем","metadata":{"id":"bZbOg0FqW-A1"}},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"T1Yx_qr-W-A2","execution":{"iopub.status.busy":"2021-12-21T11:39:45.221218Z","iopub.execute_input":"2021-12-21T11:39:45.221451Z","iopub.status.idle":"2021-12-21T11:39:45.225540Z","shell.execute_reply.started":"2021-12-21T11:39:45.221418Z","shell.execute_reply":"2021-12-21T11:39:45.224556Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"word2index = {'PAD': 0}\nvectors = []\n    \nword2vec_file = open('cc.ru.300.vec')\n    \nn_words, embedding_dim = word2vec_file.readline().split()\nn_words, embedding_dim = int(n_words), int(embedding_dim)\n\n# Zero vector for PAD\nvectors.append(np.zeros((1, embedding_dim)))\n\nprogress_bar = tqdm(desc='Read word2vec', total=n_words)\n\nwhile True:\n\n    line = word2vec_file.readline().strip()\n\n    if not line:\n        break\n        \n    current_parts = line.split()\n\n    current_word = ' '.join(current_parts[:-embedding_dim])\n\n    if current_word in word2freq:\n\n        word2index[current_word] = len(word2index)\n\n        current_vectors = current_parts[-embedding_dim:]\n        current_vectors = np.array(list(map(float, current_vectors)))\n        current_vectors = np.expand_dims(current_vectors, 0)\n\n        vectors.append(current_vectors)\n\n    progress_bar.update(1)\n\nprogress_bar.close()\n\nword2vec_file.close()\n\nvectors = np.concatenate(vectors)","metadata":{"id":"BLEgfnaWW-A4","outputId":"05846f70-6229-4df2-bcd5-68cc08e0d010","execution":{"iopub.status.busy":"2021-12-21T11:39:45.227001Z","iopub.execute_input":"2021-12-21T11:39:45.227465Z","iopub.status.idle":"2021-12-21T11:40:57.178542Z","shell.execute_reply.started":"2021-12-21T11:39:45.227428Z","shell.execute_reply":"2021-12-21T11:40:57.177723Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"len(word2index)","metadata":{"id":"AYJMzgpnW-A7","outputId":"4fec5db6-fca6-42a2-93da-be988702d797","execution":{"iopub.status.busy":"2021-12-21T11:40:57.181084Z","iopub.execute_input":"2021-12-21T11:40:57.181381Z","iopub.status.idle":"2021-12-21T11:40:57.190339Z","shell.execute_reply.started":"2021-12-21T11:40:57.181349Z","shell.execute_reply":"2021-12-21T11:40:57.189533Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"unk_words = [word for word in word2freq if word not in word2index]\nunk_counts = [word2freq[word] for word in unk_words]\nn_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n\nsub_sample_unk_words = {word: word2freq[word] for word in unk_words}\nsorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n\nprint('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\nprint('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\nprint('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\nprint()\nprint('Топ 5 невошедших слов:')\n\nfor i in range(5):\n    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])","metadata":{"id":"KE06fafiW-A8","outputId":"d6c87428-4474-4275-f300-d246364d7865","execution":{"iopub.status.busy":"2021-12-21T11:40:57.191775Z","iopub.execute_input":"2021-12-21T11:40:57.192233Z","iopub.status.idle":"2021-12-21T11:40:57.289027Z","shell.execute_reply.started":"2021-12-21T11:40:57.192196Z","shell.execute_reply":"2021-12-21T11:40:57.288270Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Потеря 2.5 % слов в датасете\nЭта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой.","metadata":{"id":"GFPNApUjW-A9"}},{"cell_type":"code","source":"import torch","metadata":{"id":"_fo1fB6JW-A-","execution":{"iopub.status.busy":"2021-12-21T11:40:57.291714Z","iopub.execute_input":"2021-12-21T11:40:57.291907Z","iopub.status.idle":"2021-12-21T11:40:58.644281Z","shell.execute_reply.started":"2021-12-21T11:40:57.291883Z","shell.execute_reply":"2021-12-21T11:40:58.643316Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"pEKAjCg3W-BA"}},{"cell_type":"code","source":"x = torch.rand(128, 64, 1024)","metadata":{"id":"D19pDyQBW-BA","execution":{"iopub.status.busy":"2021-12-21T11:40:58.649382Z","iopub.execute_input":"2021-12-21T11:40:58.649842Z","iopub.status.idle":"2021-12-21T11:40:58.834087Z","shell.execute_reply.started":"2021-12-21T11:40:58.649801Z","shell.execute_reply":"2021-12-21T11:40:58.832997Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512, batch_first=True)","metadata":{"id":"Yxsxr7edW-BB","execution":{"iopub.status.busy":"2021-12-21T11:40:58.835504Z","iopub.execute_input":"2021-12-21T11:40:58.836133Z","iopub.status.idle":"2021-12-21T11:40:58.949489Z","shell.execute_reply.started":"2021-12-21T11:40:58.836090Z","shell.execute_reply":"2021-12-21T11:40:58.948745Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm(x)","metadata":{"id":"TZy0lKr2W-BC","outputId":"4556ff61-4bd7-4ba5-da18-a26410a64d25","execution":{"iopub.status.busy":"2021-12-21T11:40:58.950623Z","iopub.execute_input":"2021-12-21T11:40:58.954109Z","iopub.status.idle":"2021-12-21T11:41:02.667251Z","shell.execute_reply.started":"2021-12-21T11:40:58.954068Z","shell.execute_reply":"2021-12-21T11:41:02.666477Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# А что GPU?","metadata":{"id":"s611e34SW-BE"}},{"cell_type":"code","source":"print('Доступна ли видеокарта:', torch.cuda.is_available())\nprint('Если недоступна, поменяйте runtime, если в колабе')","metadata":{"id":"xjFlWdgtW-BE","outputId":"93205b98-fd2b-4bea-a93f-5544f82c5a2c","execution":{"iopub.status.busy":"2021-12-21T11:41:02.672832Z","iopub.execute_input":"2021-12-21T11:41:02.673195Z","iopub.status.idle":"2021-12-21T11:41:02.726101Z","shell.execute_reply.started":"2021-12-21T11:41:02.673151Z","shell.execute_reply":"2021-12-21T11:41:02.725361Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# универсальных способ задать device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать","metadata":{"id":"jaMMD5CDW-BG","execution":{"iopub.status.busy":"2021-12-21T11:41:02.727747Z","iopub.execute_input":"2021-12-21T11:41:02.728293Z","iopub.status.idle":"2021-12-21T11:41:02.737847Z","shell.execute_reply.started":"2021-12-21T11:41:02.728254Z","shell.execute_reply":"2021-12-21T11:41:02.737029Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# перенесли x на gpu\nx_gpu = x.to(device)","metadata":{"id":"GeQCiSYdW-BH","execution":{"iopub.status.busy":"2021-12-21T11:41:02.740930Z","iopub.execute_input":"2021-12-21T11:41:02.741179Z","iopub.status.idle":"2021-12-21T11:41:04.877140Z","shell.execute_reply.started":"2021-12-21T11:41:02.741154Z","shell.execute_reply":"2021-12-21T11:41:04.876285Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# зададим lstm на gpu\nlstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\nlstm_gpu = lstm_gpu.to(device)","metadata":{"id":"S_qUdMcbW-BJ","execution":{"iopub.status.busy":"2021-12-21T11:41:04.878714Z","iopub.execute_input":"2021-12-21T11:41:04.879021Z","iopub.status.idle":"2021-12-21T11:41:05.503078Z","shell.execute_reply.started":"2021-12-21T11:41:04.878979Z","shell.execute_reply":"2021-12-21T11:41:05.502318Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm_gpu(x_gpu)","metadata":{"id":"hSUQmRgtW-BK","outputId":"44da2f5b-6421-44d9-829b-499212280ee1","execution":{"iopub.status.busy":"2021-12-21T11:41:05.504424Z","iopub.execute_input":"2021-12-21T11:41:05.504701Z","iopub.status.idle":"2021-12-21T11:41:13.499210Z","shell.execute_reply.started":"2021-12-21T11:41:05.504652Z","shell.execute_reply":"2021-12-21T11:41:13.498362Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз","metadata":{"id":"gPvqNWkQW-BM"}},{"cell_type":"code","source":"# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n# справедлива и обратная ситуация\n\n# выскочит ошибка\n# посмотрите на нее, возможно, вы еще встретитесь\n# pred = lstm_gpu(x)","metadata":{"id":"FaPKGO5aW-BN","execution":{"iopub.status.busy":"2021-12-21T11:41:13.500540Z","iopub.execute_input":"2021-12-21T11:41:13.500824Z","iopub.status.idle":"2021-12-21T11:41:13.506365Z","shell.execute_reply.started":"2021-12-21T11:41:13.500786Z","shell.execute_reply":"2021-12-21T11:41:13.504338Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Важные и не очень интуитивные моменты про LSTM и CNN в торче","metadata":{"id":"9NX5HHDOW-BO"}},{"cell_type":"markdown","source":"По умолчанию LSTM принимает данные с такой размерностью:\n```python\n(seq_len, batch, input_size)\n```\nСделано это с целью оптимизации на более низком уровне.  \nМы оперируем такими объектами:\n```python\n(batch, seq_len, input_size)\n```\nЧтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\nлибо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)","metadata":{"id":"zKr22rklW-BP"}},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"Bny8SvCgW-BQ"}},{"cell_type":"code","source":"# первый способ\nlstm = torch.nn.LSTM(1024, 512, batch_first=True)\n\npred, mem = lstm(x)","metadata":{"id":"vc-bLok2W-BQ","execution":{"iopub.status.busy":"2021-12-21T11:41:13.508583Z","iopub.execute_input":"2021-12-21T11:41:13.509238Z","iopub.status.idle":"2021-12-21T11:41:14.014668Z","shell.execute_reply.started":"2021-12-21T11:41:13.509200Z","shell.execute_reply":"2021-12-21T11:41:14.013751Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"id":"OHpit-1tW-BR","outputId":"e33f0f23-f029-4e7b-b1ff-d3b12276db82","execution":{"iopub.status.busy":"2021-12-21T11:41:14.015913Z","iopub.execute_input":"2021-12-21T11:41:14.016305Z","iopub.status.idle":"2021-12-21T11:41:14.022629Z","shell.execute_reply.started":"2021-12-21T11:41:14.016268Z","shell.execute_reply":"2021-12-21T11:41:14.021876Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512)\n\n# меняем размерность batch и seq_len местами\nx_transposed = x.transpose(0, 1)\npred_transposed, mem = lstm(x_transposed)","metadata":{"id":"ru_WzGSJW-BS","execution":{"iopub.status.busy":"2021-12-21T11:41:14.023879Z","iopub.execute_input":"2021-12-21T11:41:14.024636Z","iopub.status.idle":"2021-12-21T11:41:14.580299Z","shell.execute_reply.started":"2021-12-21T11:41:14.024598Z","shell.execute_reply":"2021-12-21T11:41:14.579194Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# у нас все еще осталась размерность (seq_len, batch, input_size)\npred_transposed.shape","metadata":{"id":"NHdBavTWW-BT","outputId":"ba454a8b-fec7-402f-a7a1-c4f9f9556e6d","execution":{"iopub.status.busy":"2021-12-21T11:41:14.581451Z","iopub.execute_input":"2021-12-21T11:41:14.582126Z","iopub.status.idle":"2021-12-21T11:41:14.587495Z","shell.execute_reply.started":"2021-12-21T11:41:14.582085Z","shell.execute_reply":"2021-12-21T11:41:14.586598Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# просто транспонируем еще раз\npred = pred_transposed.transpose(0, 1)\npred.shape","metadata":{"id":"Rcxv55j7W-BV","outputId":"f560450f-75bf-4397-d9f0-f88e3d06705c","execution":{"iopub.status.busy":"2021-12-21T11:41:14.588617Z","iopub.execute_input":"2021-12-21T11:41:14.589288Z","iopub.status.idle":"2021-12-21T11:41:14.601515Z","shell.execute_reply.started":"2021-12-21T11:41:14.589249Z","shell.execute_reply":"2021-12-21T11:41:14.600655Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Conv1d & MaxPool1d\nПримерно такая же ситуация происходит со сверточными слоями и пулингами.  \n1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \nОжидается такая размерность:\n```python\n(batch, input_size, seq_len)\n```\nМы все еще хоти подавать такую размерность:\n```python\n(batch, seq_len, input_size)\n```\nВ случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля).","metadata":{"id":"PmJt6cqkW-BW"}},{"cell_type":"code","source":"x.shape","metadata":{"id":"TyM8Xl24W-BX","outputId":"2a5512ca-bc14-43f1-804b-e71df3a7ad7e","execution":{"iopub.status.busy":"2021-12-21T11:41:14.602818Z","iopub.execute_input":"2021-12-21T11:41:14.603191Z","iopub.status.idle":"2021-12-21T11:41:14.612488Z","shell.execute_reply.started":"2021-12-21T11:41:14.603089Z","shell.execute_reply":"2021-12-21T11:41:14.611370Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"grPNMjEZW-BY"}},{"cell_type":"code","source":"# in_channels - размер входных эмбеддингов\n# out_channels - количество/какой размер эмбеддингов мы хотим получить\n# kernel_size - размер окна/н-граммы\ncnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)","metadata":{"id":"btJ-ApiOW-BY","execution":{"iopub.status.busy":"2021-12-21T11:41:14.613639Z","iopub.execute_input":"2021-12-21T11:41:14.614245Z","iopub.status.idle":"2021-12-21T11:41:14.633490Z","shell.execute_reply.started":"2021-12-21T11:41:14.614195Z","shell.execute_reply":"2021-12-21T11:41:14.632901Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# выпадет ошибка, посмотрите какая\n# pred = cnn(x)","metadata":{"id":"QIYff7YyW-Bb","execution":{"iopub.status.busy":"2021-12-21T11:41:14.634863Z","iopub.execute_input":"2021-12-21T11:41:14.635144Z","iopub.status.idle":"2021-12-21T11:41:14.639987Z","shell.execute_reply.started":"2021-12-21T11:41:14.635110Z","shell.execute_reply":"2021-12-21T11:41:14.639070Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"x_transposed = x.transpose(1, 2)\nx_transposed.shape\n# перевели в (batch, input_size, seq_len)","metadata":{"id":"7tVn6YKLW-Bd","outputId":"7a1a5f4c-b44f-4ed6-f90c-a9d00f78dfe6","execution":{"iopub.status.busy":"2021-12-21T11:41:14.643115Z","iopub.execute_input":"2021-12-21T11:41:14.643647Z","iopub.status.idle":"2021-12-21T11:41:14.650572Z","shell.execute_reply.started":"2021-12-21T11:41:14.643572Z","shell.execute_reply":"2021-12-21T11:41:14.649833Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"pred_transposed = cnn(x_transposed)\npred_transposed.shape\n# осталась разрмерность (batch, output_size, seq_len)","metadata":{"id":"2N4w6-iWW-Be","outputId":"bf29af13-5bd4-4882-f60f-b01575b100e8","execution":{"iopub.status.busy":"2021-12-21T11:41:14.651750Z","iopub.execute_input":"2021-12-21T11:41:14.652238Z","iopub.status.idle":"2021-12-21T11:41:14.927881Z","shell.execute_reply.started":"2021-12-21T11:41:14.652201Z","shell.execute_reply":"2021-12-21T11:41:14.927019Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# переведем обратно в (batch, seq_len, input_size)\npred = pred_transposed.transpose(1, 2)\npred.shape","metadata":{"id":"7-C3_phaW-Bf","outputId":"2ce7a78f-5492-404a-aeb5-2911386734d4","execution":{"iopub.status.busy":"2021-12-21T11:41:14.929261Z","iopub.execute_input":"2021-12-21T11:41:14.929593Z","iopub.status.idle":"2021-12-21T11:41:14.938073Z","shell.execute_reply.started":"2021-12-21T11:41:14.929555Z","shell.execute_reply":"2021-12-21T11:41:14.937243Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# Подготовим данные в DataLoader","metadata":{"id":"stBQ3yhqW-Bi"}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"id":"vPX_m5M4W-Bi","execution":{"iopub.status.busy":"2021-12-21T11:41:14.939706Z","iopub.execute_input":"2021-12-21T11:41:14.940354Z","iopub.status.idle":"2021-12-21T11:41:14.944612Z","shell.execute_reply.started":"2021-12-21T11:41:14.940315Z","shell.execute_reply":"2021-12-21T11:41:14.943798Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"'UNK' in word2index","metadata":{"id":"hV76BdN0W-Bj","outputId":"befb4dd0-0df1-4ada-fe1d-dae478226f35","execution":{"iopub.status.busy":"2021-12-21T11:41:14.946302Z","iopub.execute_input":"2021-12-21T11:41:14.946948Z","iopub.status.idle":"2021-12-21T11:41:14.954679Z","shell.execute_reply.started":"2021-12-21T11:41:14.946812Z","shell.execute_reply":"2021-12-21T11:41:14.953542Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"id":"INB_dPAnW-Bk","outputId":"8bb90efa-4c9c-4908-c872-393906ed8619","execution":{"iopub.status.busy":"2021-12-21T11:41:14.956017Z","iopub.execute_input":"2021-12-21T11:41:14.956286Z","iopub.status.idle":"2021-12-21T11:41:14.968572Z","shell.execute_reply.started":"2021-12-21T11:41:14.956252Z","shell.execute_reply":"2021-12-21T11:41:14.967910Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"# Замапим категории в индексы","metadata":{"id":"1qv1mKAeW-Bl"}},{"cell_type":"code","source":"cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}","metadata":{"id":"iHeFzZe1W-Bl","execution":{"iopub.status.busy":"2021-12-21T11:41:14.969737Z","iopub.execute_input":"2021-12-21T11:41:14.970237Z","iopub.status.idle":"2021-12-21T11:41:14.995054Z","shell.execute_reply.started":"2021-12-21T11:41:14.970199Z","shell.execute_reply":"2021-12-21T11:41:14.994144Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"cat_mapper","metadata":{"id":"X3x9QhXYW-Bn","outputId":"0a4dff58-d739-4847-f818-c3e0d321e78a","execution":{"iopub.status.busy":"2021-12-21T11:41:14.997320Z","iopub.execute_input":"2021-12-21T11:41:14.997819Z","iopub.status.idle":"2021-12-21T11:41:15.003710Z","shell.execute_reply.started":"2021-12-21T11:41:14.997776Z","shell.execute_reply":"2021-12-21T11:41:15.002892Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"data.category = data.category.map(cat_mapper)","metadata":{"id":"ef--8SWbW-Bo","execution":{"iopub.status.busy":"2021-12-21T11:41:15.006405Z","iopub.execute_input":"2021-12-21T11:41:15.006761Z","iopub.status.idle":"2021-12-21T11:41:15.034277Z","shell.execute_reply.started":"2021-12-21T11:41:15.006724Z","shell.execute_reply":"2021-12-21T11:41:15.033564Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Читалка данных","metadata":{"id":"vc48ALg_W-Bp"}},{"cell_type":"markdown","source":"## Что происходит ниже\n1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n1. Загружаем данные:\n    1. Проходимся по датасету\n    1. Предобрабатываем каждый текст в датасете\n    1. Индексируем его\n    1. Паддим до нужной длины\n1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n","metadata":{"id":"WFIQEv6nvE4c"}},{"cell_type":"code","source":"class WordData(Dataset):\n    \n    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n        \n        super().__init__()\n        \n        self.x_data = []\n        self.y_data = y_data\n        \n        self.word2index = word2index\n        self.sequence_length = sequence_length\n        \n        self.pad_token = pad_token\n        self.pad_index = self.word2index[self.pad_token]\n        \n        self.load(x_data, verbose=verbose)\n        \n    @staticmethod\n    def process_text(text):\n        \n        # Место для вашей предобработки\n        \n        words = wordpunct_tokenize(text.lower())\n        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n        return words\n        \n    def load(self, data, verbose=True):\n        \n        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n        \n        for text in data_iterator:\n            \n            words = self.process_text(text)\n            \n            indexed_words = self.indexing(words)\n            \n            self.x_data.append(indexed_words)\n    \n    def indexing(self, tokenized_text):\n\n        # здесь мы не используем токен UNK, потому что мы его специально не учили\n        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n        # поэтому просто выбрасываем наши неизветсные слова\n        \n        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n    \n    def padding(self, sequence):\n        \n        # Ограничить длину self.sequence_length\n        # если длина меньше максимально - западить\n        if len(sequence)< self.sequence_length:\n          add_pad = self.sequence_length - len(sequence)\n          return sequence+[self.pad_index]*add_pad\n        else:\n          return sequence[:self.sequence_length]\n    \n    def __len__(self):\n        \n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        \n        x = self.x_data[idx]\n        x = self.padding(x)\n        x = torch.Tensor(x).long()\n        \n        y = self.y_data[idx]\n        \n        return x, y","metadata":{"id":"ZkX8SC_sW-Bp","execution":{"iopub.status.busy":"2021-12-21T11:41:15.035526Z","iopub.execute_input":"2021-12-21T11:41:15.036283Z","iopub.status.idle":"2021-12-21T11:41:15.048609Z","shell.execute_reply.started":"2021-12-21T11:41:15.036238Z","shell.execute_reply":"2021-12-21T11:41:15.047884Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","metadata":{"id":"R3WW8V9lyLm0","execution":{"iopub.status.busy":"2021-12-21T11:41:15.049643Z","iopub.execute_input":"2021-12-21T11:41:15.050268Z","iopub.status.idle":"2021-12-21T11:41:15.061384Z","shell.execute_reply.started":"2021-12-21T11:41:15.050221Z","shell.execute_reply":"2021-12-21T11:41:15.060692Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n\ntrain_dataset = WordData(list(x_train), list(y_train), word2index)\ntrain_loader = DataLoader(train_dataset, batch_size=64)\n\nvalidation_dataset = WordData(list(x_validation), list(y_validation), word2index)\nvalidation_loader = DataLoader(validation_dataset, batch_size=64)","metadata":{"id":"Lnc2nD8gW-Br","outputId":"d72654f9-7a85-49a6-e0c2-429b5db04c4e","execution":{"iopub.status.busy":"2021-12-21T11:41:15.063648Z","iopub.execute_input":"2021-12-21T11:41:15.064383Z","iopub.status.idle":"2021-12-21T11:41:18.431949Z","shell.execute_reply.started":"2021-12-21T11:41:15.064358Z","shell.execute_reply":"2021-12-21T11:41:18.431102Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"for x, y in train_loader:\n    break","metadata":{"id":"dGeftxdgW-Br","execution":{"iopub.status.busy":"2021-12-21T11:41:18.433475Z","iopub.execute_input":"2021-12-21T11:41:18.433771Z","iopub.status.idle":"2021-12-21T11:41:18.444414Z","shell.execute_reply.started":"2021-12-21T11:41:18.433732Z","shell.execute_reply":"2021-12-21T11:41:18.443691Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"id":"nNkGQffBW-Bs","outputId":"77e1ecb5-4bdc-414d-fb89-b7650ed25fba","execution":{"iopub.status.busy":"2021-12-21T11:41:18.445526Z","iopub.execute_input":"2021-12-21T11:41:18.446811Z","iopub.status.idle":"2021-12-21T11:41:18.455303Z","shell.execute_reply.started":"2021-12-21T11:41:18.446771Z","shell.execute_reply":"2021-12-21T11:41:18.454438Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"id":"fxUk4nGcW-Bt","outputId":"bae977fd-25ef-4fd7-c451-402e8ea287a4","execution":{"iopub.status.busy":"2021-12-21T11:41:18.457148Z","iopub.execute_input":"2021-12-21T11:41:18.457646Z","iopub.status.idle":"2021-12-21T11:41:18.463938Z","shell.execute_reply.started":"2021-12-21T11:41:18.457609Z","shell.execute_reply":"2021-12-21T11:41:18.463205Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Обучить нейронку","metadata":{"id":"Zy0dkkTIW-Bw"}},{"cell_type":"code","source":"from math import sqrt\n\nclass model_with_att(torch.nn.Module):\n  def __init__(self, matrix_w, n): #n - количетсво категорий\n        \n        super().__init__()\n\n        self.n = n\n        \n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        self.LSTM = torch.nn.LSTM(300, 256, \n                                  num_layers=2, bidirectional=True, dropout=0.1,\n                                  batch_first=True)\n        \n        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=3, stride=1)\n        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=4, stride=1)\n        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=5, stride=1)\n\n        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n        self.relu = torch.nn.ReLU()\n        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n\n        \n  def forward(self, x):\n      x_emb = self.emb_layer(x) #примените эмбеддинги\n      # транспонируйте тензор для лстм как было описано выше\n      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n      # транспонируйте обратно\n\n      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n      x_k = self.k_proj(x)\n      x_v = self.v_proj(x)\n\n      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_q.size(-1))\n      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n      attention_vectors = torch.bmm(att_dist, x_v)\n\n      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n\n      x_cnn3 = self.cnn_3gr(x_att)\n      x_cnn4 = self.cnn_4gr(x_att)\n      x_cnn5 = self.cnn_5gr(x_att)\n\n      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n      sc, _ = x_cnn4.max(dim= -1,)\n      thr, _ = x_cnn5.max(dim= -1,)\n      \n      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n      \n      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n      x = self.relu(x)    \n      x = self.linear_2(x)\n    \n      return x","metadata":{"id":"3wwkxZm1vE43","execution":{"iopub.status.busy":"2021-12-21T11:41:18.465493Z","iopub.execute_input":"2021-12-21T11:41:18.466079Z","iopub.status.idle":"2021-12-21T11:41:18.482535Z","shell.execute_reply.started":"2021-12-21T11:41:18.466042Z","shell.execute_reply":"2021-12-21T11:41:18.481520Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"n_classes = data.category.unique().shape[0]","metadata":{"id":"jFbyUXLE0WPv","execution":{"iopub.status.busy":"2021-12-21T11:41:18.483560Z","iopub.execute_input":"2021-12-21T11:41:18.485799Z","iopub.status.idle":"2021-12-21T11:41:18.498057Z","shell.execute_reply.started":"2021-12-21T11:41:18.485762Z","shell.execute_reply":"2021-12-21T11:41:18.497281Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model = model_with_att(vectors, n_classes)","metadata":{"id":"OZgh4ONx0HvT","execution":{"iopub.status.busy":"2021-12-21T11:41:18.500634Z","iopub.execute_input":"2021-12-21T11:41:18.500905Z","iopub.status.idle":"2021-12-21T11:41:18.629460Z","shell.execute_reply.started":"2021-12-21T11:41:18.500872Z","shell.execute_reply":"2021-12-21T11:41:18.628719Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model #если сделать batch_first=True, то можно не транспонировать батчи","metadata":{"id":"CNO6VSbJgQ36","outputId":"409a1cc5-8448-4a0e-ec43-77d8d6f79683","execution":{"iopub.status.busy":"2021-12-21T11:41:18.630715Z","iopub.execute_input":"2021-12-21T11:41:18.631058Z","iopub.status.idle":"2021-12-21T11:41:18.636887Z","shell.execute_reply.started":"2021-12-21T11:41:18.631019Z","shell.execute_reply":"2021-12-21T11:41:18.636142Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    pred = model(x)","metadata":{"id":"E66MWNgM0QKM","execution":{"iopub.status.busy":"2021-12-21T11:41:18.638395Z","iopub.execute_input":"2021-12-21T11:41:18.638888Z","iopub.status.idle":"2021-12-21T11:41:18.829000Z","shell.execute_reply.started":"2021-12-21T11:41:18.638851Z","shell.execute_reply":"2021-12-21T11:41:18.828236Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"id":"ErboeQbv0dnC","execution":{"iopub.status.busy":"2021-12-21T11:41:18.830144Z","iopub.execute_input":"2021-12-21T11:41:18.830416Z","iopub.status.idle":"2021-12-21T11:41:18.835792Z","shell.execute_reply.started":"2021-12-21T11:41:18.830381Z","shell.execute_reply":"2021-12-21T11:41:18.835057Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"bL6zIZSt0h9W","execution":{"iopub.status.busy":"2021-12-21T11:41:18.836900Z","iopub.execute_input":"2021-12-21T11:41:18.837588Z","iopub.status.idle":"2021-12-21T11:41:18.843848Z","shell.execute_reply.started":"2021-12-21T11:41:18.837551Z","shell.execute_reply":"2021-12-21T11:41:18.843089Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"id":"Vsxw4M2m0m2B","execution":{"iopub.status.busy":"2021-12-21T11:41:18.845144Z","iopub.execute_input":"2021-12-21T11:41:18.845623Z","iopub.status.idle":"2021-12-21T11:41:18.898037Z","shell.execute_reply.started":"2021-12-21T11:41:18.845587Z","shell.execute_reply":"2021-12-21T11:41:18.897389Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"id":"7rUTc0l60pV9","outputId":"ea81b9b3-b1d3-4122-869b-da0592397d76","execution":{"iopub.status.busy":"2021-12-21T11:41:18.899244Z","iopub.execute_input":"2021-12-21T11:41:18.899638Z","iopub.status.idle":"2021-12-21T11:47:58.006862Z","shell.execute_reply.started":"2021-12-21T11:41:18.899602Z","shell.execute_reply":"2021-12-21T11:47:58.006067Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо","metadata":{"id":"1TMaPbh3oWwc"}},{"cell_type":"code","source":"for instance in list(tqdm._instances): \n    tqdm._decr_instances(instance)","metadata":{"id":"_aPjTQcR0vm2","outputId":"03d584f8-2f8c-4e0b-ae8e-7112f6624275","execution":{"iopub.status.busy":"2021-12-21T11:49:01.927254Z","iopub.execute_input":"2021-12-21T11:49:01.927808Z","iopub.status.idle":"2021-12-21T11:49:01.932655Z","shell.execute_reply.started":"2021-12-21T11:49:01.927766Z","shell.execute_reply":"2021-12-21T11:49:01.931404Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"# Оценка\n1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов ","metadata":{}},{"cell_type":"markdown","source":"# Что я делал\n\n1. Поигрался с оптимайзерами и их гиперпараметрами - не помогло\n2. Добавил дропаут - чуть-чуть стало лучше\n3. Пробовал менять предобработку - стало хуже (лемматизация)\n4. Поигрался с функциями акттивации, Parametric ReLU вроде работает лучше P.S. увидел сообщение в чате, согласен что немного тупо надеяться на функцию активации при шумных данных","metadata":{}},{"cell_type":"code","source":"from math import sqrt\n\nclass model_improved(torch.nn.Module):\n  def __init__(self, matrix_w, n): #n - количетсво категорий\n        \n        super().__init__()\n\n        self.n = n\n        \n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        self.LSTM = torch.nn.LSTM(300, 256, \n                                  num_layers=2, bidirectional=True, dropout=0.1,\n                                  batch_first=True)\n        \n        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=3, stride=1)\n        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=4, stride=1)\n        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=5, stride=1)\n\n        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n        self.relu = torch.nn.PReLU()\n        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n        self.dropout = torch.nn.Dropout(p=0.3)\n\n        \n  def forward(self, x):\n      x_emb = self.emb_layer(x) #примените эмбеддинги\n      # транспонируйте тензор для лстм как было описано выше\n      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n      # транспонируйте обратно\n\n      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n      x_k = self.k_proj(x)\n      x_v = self.v_proj(x)\n\n      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_q.size(-1))\n      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n      attention_vectors = torch.bmm(att_dist, x_v)\n\n      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n\n      x_cnn3 = self.cnn_3gr(x_att)\n      x_cnn4 = self.cnn_4gr(x_att)\n      x_cnn5 = self.cnn_5gr(x_att)\n\n      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n      sc, _ = x_cnn4.max(dim= -1,)\n      thr, _ = x_cnn5.max(dim= -1,)\n      \n      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n      \n      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n      x = self.dropout(self.relu(x))    \n      x = self.linear_2(x)\n    \n      return x","metadata":{"id":"e5BgHdtW2sO3","execution":{"iopub.status.busy":"2021-12-21T11:49:06.044806Z","iopub.execute_input":"2021-12-21T11:49:06.045309Z","iopub.status.idle":"2021-12-21T11:49:06.062156Z","shell.execute_reply.started":"2021-12-21T11:49:06.045266Z","shell.execute_reply":"2021-12-21T11:49:06.061405Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"model = model_improved(vectors, n_classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:49:06.977038Z","iopub.execute_input":"2021-12-21T11:49:06.977301Z","iopub.status.idle":"2021-12-21T11:49:07.106086Z","shell.execute_reply.started":"2021-12-21T11:49:06.977269Z","shell.execute_reply":"2021-12-21T11:49:07.105321Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:49:07.820994Z","iopub.execute_input":"2021-12-21T11:49:07.821585Z","iopub.status.idle":"2021-12-21T11:49:07.871369Z","shell.execute_reply.started":"2021-12-21T11:49:07.821542Z","shell.execute_reply":"2021-12-21T11:49:07.870683Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:49:08.618756Z","iopub.execute_input":"2021-12-21T11:49:08.619488Z","iopub.status.idle":"2021-12-21T11:55:36.864242Z","shell.execute_reply.started":"2021-12-21T11:49:08.619441Z","shell.execute_reply":"2021-12-21T11:55:36.863355Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"P.S. Решил запустить все еще раз, и видимо, мне попался какой-то очень крутой сид, т.к. на первой модели точность 0.846 и побороть ее на улучшенной модели не вышло. На предыдущих тестах с такими же параметрами модели было все позитивнее: 0.841, затем 0.842, чуть чуть, но улучшилось. Могу отправить скрины если надо, сохранял ровно на такой случай ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:55:43.827202Z","iopub.execute_input":"2021-12-21T11:55:43.827469Z","iopub.status.idle":"2021-12-21T11:55:52.755785Z","shell.execute_reply.started":"2021-12-21T11:55:43.827437Z","shell.execute_reply":"2021-12-21T11:55:52.754907Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":"# Наши данные","metadata":{}},{"cell_type":"code","source":"sentences = data.text.values\nlabels = data.category.values","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:55:54.420402Z","iopub.execute_input":"2021-12-21T11:55:54.420714Z","iopub.status.idle":"2021-12-21T11:55:54.426734Z","shell.execute_reply.started":"2021-12-21T11:55:54.420658Z","shell.execute_reply":"2021-12-21T11:55:54.425997Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"len(data.category.unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:56:51.580566Z","iopub.execute_input":"2021-12-21T11:56:51.580854Z","iopub.status.idle":"2021-12-21T11:56:51.588499Z","shell.execute_reply.started":"2021-12-21T11:56:51.580823Z","shell.execute_reply":"2021-12-21T11:56:51.587739Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Load the BERT tokenizer.\nprint('Loading BERT tokenizer...')\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:34:53.064131Z","iopub.execute_input":"2021-12-21T12:34:53.064416Z","iopub.status.idle":"2021-12-21T12:34:55.563216Z","shell.execute_reply.started":"2021-12-21T12:34:53.064382Z","shell.execute_reply":"2021-12-21T12:34:55.562482Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# Print the original sentence.\nprint(' Original: ', sentences[0])\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(sentences[0]))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:34:55.609834Z","iopub.execute_input":"2021-12-21T12:34:55.610052Z","iopub.status.idle":"2021-12-21T12:34:55.619031Z","shell.execute_reply.started":"2021-12-21T12:34:55.610026Z","shell.execute_reply":"2021-12-21T12:34:55.616448Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:34:56.613607Z","iopub.execute_input":"2021-12-21T12:34:56.615312Z","iopub.status.idle":"2021-12-21T12:34:56.620449Z","shell.execute_reply.started":"2021-12-21T12:34:56.615270Z","shell.execute_reply":"2021-12-21T12:34:56.619715Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# Tokenize all of the sentences and map the tokens to thier word IDs.\ninput_ids = []\n\n# For every sentence...\nfor sent in tqdm(sentences):\n    # `encode` will:\n    #   (1) Tokenize the sentence.\n    #   (2) Prepend the `[CLS]` token to the start.\n    #   (3) Append the `[SEP]` token to the end.\n    #   (4) Map tokens to their IDs.\n    encoded_sent = tokenizer.encode(\n                        sent,                      # Sentence to encode.\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n\n                        # This function also supports truncation and conversion\n                        # to pytorch tensors, but we need to do padding, so we\n                        # can't use these features :( .\n                        #max_length = 128,          # Truncate all sentences.\n                        #return_tensors = 'pt',     # Return pytorch tensors.\n                   )\n    \n    # Add the encoded sentence to the list.\n    input_ids.append(encoded_sent)\n\n# Print sentence 0, now as a list of IDs.\nprint('Original: ', sentences[0])\nprint('Token IDs:', input_ids[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:36:03.858394Z","iopub.execute_input":"2021-12-21T12:36:03.858787Z","iopub.status.idle":"2021-12-21T12:38:18.943797Z","shell.execute_reply.started":"2021-12-21T12:36:03.858741Z","shell.execute_reply":"2021-12-21T12:38:18.943061Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"print('Max sentence length: ', max([len(sen) for sen in input_ids]))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:18.945604Z","iopub.execute_input":"2021-12-21T12:38:18.946397Z","iopub.status.idle":"2021-12-21T12:38:18.979083Z","shell.execute_reply.started":"2021-12-21T12:38:18.946359Z","shell.execute_reply":"2021-12-21T12:38:18.978346Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"# We'll borrow the `pad_sequences` utility function to do this.\nfrom keras.preprocessing.sequence import pad_sequences\n\n# Set the maximum sequence length.\n# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n# maximum training sentence length of 47...\nMAX_LEN = 70\n\nprint('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n\nprint('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n\n# Pad our input tokens with value 0.\n# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n# as opposed to the beginning.\ninput_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n                          value=0, truncating=\"post\", padding=\"post\")\n\nprint('\\nDone.')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:18.980184Z","iopub.execute_input":"2021-12-21T12:38:18.980501Z","iopub.status.idle":"2021-12-21T12:38:21.210918Z","shell.execute_reply.started":"2021-12-21T12:38:18.980461Z","shell.execute_reply":"2021-12-21T12:38:21.210194Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# Create attention masks\nattention_masks = []\n\n# For each sentence...\nfor sent in tqdm(input_ids):\n    \n    # Create the attention mask.\n    #   - If a token ID is 0, then it's padding, set the mask to 0.\n    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n    att_mask = [int(token_id > 0) for token_id in sent]\n    \n    # Store the attention mask for this sentence.\n    attention_masks.append(att_mask)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:21.212050Z","iopub.execute_input":"2021-12-21T12:38:21.214832Z","iopub.status.idle":"2021-12-21T12:38:37.661176Z","shell.execute_reply.started":"2021-12-21T12:38:21.214793Z","shell.execute_reply":"2021-12-21T12:38:37.660443Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"# Use train_test_split to split our data into train and validation sets for\n# training\nfrom sklearn.model_selection import train_test_split\n\n# Use 90% for training and 10% for validation.\ntrain_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n                                                            random_state=2018, test_size=0.1)\n# Do the same for the masks.\ntrain_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n                                             random_state=2018, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:37.663697Z","iopub.execute_input":"2021-12-21T12:38:37.663980Z","iopub.status.idle":"2021-12-21T12:38:37.874264Z","shell.execute_reply.started":"2021-12-21T12:38:37.663942Z","shell.execute_reply":"2021-12-21T12:38:37.873290Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# Convert all inputs and labels into torch tensors, the required datatype \n# for our model.\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\n\ntrain_labels = torch.tensor(train_labels)\nvalidation_labels = torch.tensor(validation_labels)\n\ntrain_masks = torch.tensor(train_masks)\nvalidation_masks = torch.tensor(validation_masks)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:37.875558Z","iopub.execute_input":"2021-12-21T12:38:37.875844Z","iopub.status.idle":"2021-12-21T12:38:39.949086Z","shell.execute_reply.started":"2021-12-21T12:38:37.875804Z","shell.execute_reply":"2021-12-21T12:38:39.948282Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"Поставим батч побольше, а то ну очень уж долго","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n# The DataLoader needs to know our batch size for training, so we specify it \n# here.\n# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n# 16 or 32.\n\nbatch_size = 64\n\n# Create the DataLoader for our training set.\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# Create the DataLoader for our validation set.\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:39.950357Z","iopub.execute_input":"2021-12-21T12:38:39.950617Z","iopub.status.idle":"2021-12-21T12:38:39.964166Z","shell.execute_reply.started":"2021-12-21T12:38:39.950583Z","shell.execute_reply":"2021-12-21T12:38:39.963507Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, AdamW, BertConfig\n\n# Load BertForSequenceClassification, the pretrained BERT model with a single \n# linear classification layer on top. \nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# Tell pytorch to run this model on the GPU.\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:39.965557Z","iopub.execute_input":"2021-12-21T12:38:39.966040Z","iopub.status.idle":"2021-12-21T12:38:42.769930Z","shell.execute_reply.started":"2021-12-21T12:38:39.966001Z","shell.execute_reply":"2021-12-21T12:38:42.768868Z"},"trusted":true},"execution_count":147,"outputs":[]},{"cell_type":"code","source":"b = model.bert.pooler.dense.weight\nc = model.classifier.weight\nb = b.cpu().detach().numpy()\nc = c.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.190498Z","iopub.execute_input":"2021-12-21T14:14:46.190848Z","iopub.status.idle":"2021-12-21T14:14:46.196377Z","shell.execute_reply.started":"2021-12-21T14:14:46.190806Z","shell.execute_reply":"2021-12-21T14:14:46.195577Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# Get all of the model's parameters as a list of tuples.\nparams = list(model.named_parameters())\n\nprint('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n\nprint('==== Embedding Layer ====\\n')\n\nfor p in params[0:5]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\n\nfor p in params[5:21]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layer ====\\n')\n\nfor p in params[-4:]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.199775Z","iopub.execute_input":"2021-12-21T14:14:46.200296Z","iopub.status.idle":"2021-12-21T14:14:46.213014Z","shell.execute_reply.started":"2021-12-21T14:14:46.200260Z","shell.execute_reply":"2021-12-21T14:14:46.211565Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n# I believe the 'W' stands for 'Weight Decay fix\"\noptimizer = AdamW(model.parameters(),\n                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.214596Z","iopub.execute_input":"2021-12-21T14:14:46.215502Z","iopub.status.idle":"2021-12-21T14:14:46.223826Z","shell.execute_reply.started":"2021-12-21T14:14:46.215464Z","shell.execute_reply":"2021-12-21T14:14:46.222981Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\n# Number of training epochs (authors recommend between 2 and 4)\nepochs = 4\n\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 100, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.224925Z","iopub.execute_input":"2021-12-21T14:14:46.226782Z","iopub.status.idle":"2021-12-21T14:14:46.232380Z","shell.execute_reply.started":"2021-12-21T14:14:46.226731Z","shell.execute_reply":"2021-12-21T14:14:46.231592Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":"Перепишем метрику, чтобы былл f score а не accuracy","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(pred_flat, labels_flat, average='micro')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:42.814292Z","iopub.execute_input":"2021-12-21T12:38:42.815225Z","iopub.status.idle":"2021-12-21T12:38:42.823008Z","shell.execute_reply.started":"2021-12-21T12:38:42.815194Z","shell.execute_reply":"2021-12-21T12:38:42.822093Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:42.826326Z","iopub.execute_input":"2021-12-21T12:38:42.826582Z","iopub.status.idle":"2021-12-21T12:38:42.832270Z","shell.execute_reply.started":"2021-12-21T12:38:42.826554Z","shell.execute_reply":"2021-12-21T12:38:42.831436Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"import random\n\n# This training code is based on the `run_glue.py` script here:\n# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n# Store the average loss after each epoch so we can plot them.\nloss_values = []\n\n# For each epoch...\nfor epoch_i in range(0, epochs):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    \n    # Perform one full pass over the training set.\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    # Measure how long the training epoch takes.\n    t0 = time.time()\n\n    # Reset the total loss for this epoch.\n    total_loss = 0\n\n    # Put the model into training mode. Don't be mislead--the call to \n    # `train` just changes the *mode*, it doesn't *perform* the training.\n    # `dropout` and `batchnorm` layers behave differently during training\n    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n    model.train()\n\n    # For each batch of training data...\n    for step, batch in enumerate(train_dataloader):\n\n        # Progress update every 40 batches.\n        if step % 40 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n        # `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        # Always clear any previously calculated gradients before performing a\n        # backward pass. PyTorch doesn't do this automatically because \n        # accumulating the gradients is \"convenient while training RNNs\". \n        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n        model.zero_grad()        \n\n        # Perform a forward pass (evaluate the model on this training batch).\n        # This will return the loss (rather than the model output) because we\n        # have provided the `labels`.\n        # The documentation for this `model` function is here: \n        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n        outputs = model(b_input_ids, \n                    token_type_ids=None, \n                    attention_mask=b_input_mask, \n                    labels=b_labels)\n        \n        # The call to `model` always returns a tuple, so we need to pull the \n        # loss value out of the tuple.\n        loss = outputs[0]\n\n        # Accumulate the training loss over all of the batches so that we can\n        # calculate the average loss at the end. `loss` is a Tensor containing a\n        # single value; the `.item()` function just returns the Python value \n        # from the tensor.\n        total_loss += loss.item()\n\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n\n        # Clip the norm of the gradients to 1.0.\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters and take a step using the computed gradient.\n        # The optimizer dictates the \"update rule\"--how the parameters are\n        # modified based on their gradients, the learning rate, etc.\n        optimizer.step()\n\n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over the training data.\n    avg_train_loss = total_loss / len(train_dataloader)            \n    \n    # Store the loss value for plotting the learning curve.\n    loss_values.append(avg_train_loss)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n        \n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n    # Put the model in evaluation mode--the dropout layers behave differently\n    # during evaluation.\n    model.eval()\n\n    # Tracking variables \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n\n    # Evaluate data for one epoch\n    for batch in validation_dataloader:\n        \n        # Add batch to GPU\n        batch = tuple(t.to(device) for t in batch)\n        \n        # Unpack the inputs from our dataloader\n        b_input_ids, b_input_mask, b_labels = batch\n        \n        # Telling the model not to compute or store gradients, saving memory and\n        # speeding up validation\n        with torch.no_grad():        \n\n            # Forward pass, calculate logit predictions.\n            # This will return the logits rather than the loss because we have\n            # not provided labels.\n            # token_type_ids is the same as the \"segment ids\", which \n            # differentiates sentence 1 and 2 in 2-sentence tasks.\n            # The documentation for this `model` function is here: \n            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n            outputs = model(b_input_ids, \n                            token_type_ids=None, \n                            attention_mask=b_input_mask)\n        \n        # Get the \"logits\" output by the model. The \"logits\" are the output\n        # values prior to applying an activation function like the softmax.\n        logits = outputs[0]\n\n        # Move logits and labels to CPU\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        \n        # Calculate the accuracy for this batch of test sentences.\n        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n        \n        # Accumulate the total accuracy.\n        eval_accuracy += tmp_eval_accuracy\n\n        # Track the number of batches\n        nb_eval_steps += 1\n\n    # Report the final accuracy for this validation run.\n    print(\"  FSCORE: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n\nprint(\"\")\nprint(\"Training complete!\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:42.842803Z","iopub.execute_input":"2021-12-21T12:38:42.843231Z","iopub.status.idle":"2021-12-21T14:14:46.188308Z","shell.execute_reply.started":"2021-12-21T12:38:42.843195Z","shell.execute_reply":"2021-12-21T14:14:46.187381Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}