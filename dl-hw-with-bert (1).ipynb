{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas\n!pip install torch\n!pip install nltk\n!pip install tqdm\n!pip install seaborn\n!pip install numpy\n!pip install sklearn","metadata":{"id":"Y0fOWhqwW-AT","outputId":"41f40fd4-ebae-43e8-fd1c-41db3fb72471","execution":{"iopub.status.busy":"2021-12-21T11:37:01.930422Z","iopub.execute_input":"2021-12-21T11:37:01.931307Z","iopub.status.idle":"2021-12-21T11:37:53.613494Z","shell.execute_reply.started":"2021-12-21T11:37:01.931164Z","shell.execute_reply":"2021-12-21T11:37:53.612645Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.19.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.9.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.10.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.62.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (0.11.2)\nRequirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.7/site-packages (from seaborn) (1.3.4)\nRequirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.7/site-packages (from seaborn) (3.5.0)\nRequirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.7/site-packages (from seaborn) (1.7.2)\nRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from seaborn) (1.19.5)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (4.28.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (3.0.6)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (21.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\nRequirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (6.3.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (59.1.1)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib>=2.2->seaborn) (1.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.19.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn) (0.23.2)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.1.0)\nRequirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.5)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (3.0.0)\nRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.7.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')","metadata":{"id":"u3wugeOHW-AV","outputId":"7979e6ad-bff3-4493-c0e7-a9666383f9ae","execution":{"iopub.status.busy":"2021-12-21T11:37:53.616515Z","iopub.execute_input":"2021-12-21T11:37:53.616821Z","iopub.status.idle":"2021-12-21T11:37:54.781197Z","shell.execute_reply.started":"2021-12-21T11:37:53.616783Z","shell.execute_reply":"2021-12-21T11:37:54.780454Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Скачиваем данные","metadata":{"id":"m9XIrxSmW-AX"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv","metadata":{"id":"ep1FB3IBW-AY","outputId":"ed833b2b-3b1a-492a-d9a3-ad845a9074c0","execution":{"iopub.status.busy":"2021-12-21T11:37:54.782685Z","iopub.execute_input":"2021-12-21T11:37:54.783185Z","iopub.status.idle":"2021-12-21T11:37:57.012464Z","shell.execute_reply.started":"2021-12-21T11:37:54.783144Z","shell.execute_reply":"2021-12-21T11:37:57.011628Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2021-12-21 11:37:55--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 28717126 (27M) [text/plain]\nSaving to: ‘answers_subsample.csv.1’\n\nanswers_subsample.c 100%[===================>]  27.39M  --.-KB/s    in 0.1s    \n\n2021-12-21 11:37:56 (241 MB/s) - ‘answers_subsample.csv.1’ saved [28717126/28717126]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# если ругается на то, что нет wget\n# !apt-get install wget","metadata":{"id":"BWA7IClKW-Aa","execution":{"iopub.status.busy":"2021-12-21T11:37:57.015503Z","iopub.execute_input":"2021-12-21T11:37:57.015820Z","iopub.status.idle":"2021-12-21T11:37:57.019886Z","shell.execute_reply.started":"2021-12-21T11:37:57.015779Z","shell.execute_reply":"2021-12-21T11:37:57.018841Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!ls -l","metadata":{"id":"qJpFTPpsW-Ac","outputId":"614d0244-d82c-43fd-c756-c33a3383fa30","execution":{"iopub.status.busy":"2021-12-21T11:37:57.021367Z","iopub.execute_input":"2021-12-21T11:37:57.021627Z","iopub.status.idle":"2021-12-21T11:37:57.689219Z","shell.execute_reply.started":"2021-12-21T11:37:57.021589Z","shell.execute_reply":"2021-12-21T11:37:57.688347Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"total 4486192\n---------- 1 root root        263 Dec 21 10:47 __notebook_source__.ipynb\n-rw-r--r-- 1 root root   28717126 Dec 21 10:49 answers_subsample.csv\n-rw-r--r-- 1 root root   28717126 Dec 21 11:37 answers_subsample.csv.1\n-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"id":"qmzaEwy9W-Ae","execution":{"iopub.status.busy":"2021-12-21T11:37:57.691908Z","iopub.execute_input":"2021-12-21T11:37:57.692521Z","iopub.status.idle":"2021-12-21T11:37:57.697277Z","shell.execute_reply.started":"2021-12-21T11:37:57.692484Z","shell.execute_reply":"2021-12-21T11:37:57.696407Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('answers_subsample.csv')","metadata":{"id":"BbDKxq4EW-Ag","execution":{"iopub.status.busy":"2021-12-21T11:37:57.699101Z","iopub.execute_input":"2021-12-21T11:37:57.699711Z","iopub.status.idle":"2021-12-21T11:37:58.345820Z","shell.execute_reply.started":"2021-12-21T11:37:57.699646Z","shell.execute_reply":"2021-12-21T11:37:58.345050Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"id":"hcAdsbS7W-Ai","outputId":"fe4de523-6803-40cd-ea40-a993217c57d3","execution":{"iopub.status.busy":"2021-12-21T11:37:58.347012Z","iopub.execute_input":"2021-12-21T11:37:58.347271Z","iopub.status.idle":"2021-12-21T11:37:58.364564Z","shell.execute_reply.started":"2021-12-21T11:37:58.347237Z","shell.execute_reply":"2021-12-21T11:37:58.363795Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        category                                               text\n0       business  Могут ли в россельхозбанке дать в залог норков...\n1            law  Может ли срочник перевестись на контракт после...\n2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n3       business  В чем смысл криптовалюты, какая от неё выгода ...\n4            law                 часть 1 статья 158 похитил телефон\n...          ...                                                ...\n237774     relax                                  елку нарядили? =)\n237775       law  Имеется переработка при 75% ставки, отгулы не ...\n237776      food  Попробовала варить рис с половиной кубика для ...\n237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n237778  business  Подскажите какие риски бывают в семье среднест...\n\n[237779 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>business</td>\n      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>law</td>\n      <td>Может ли срочник перевестись на контракт после...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>business</td>\n      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>business</td>\n      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>law</td>\n      <td>часть 1 статья 158 похитил телефон</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237774</th>\n      <td>relax</td>\n      <td>елку нарядили? =)</td>\n    </tr>\n    <tr>\n      <th>237775</th>\n      <td>law</td>\n      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n    </tr>\n    <tr>\n      <th>237776</th>\n      <td>food</td>\n      <td>Попробовала варить рис с половиной кубика для ...</td>\n    </tr>\n    <tr>\n      <th>237777</th>\n      <td>food</td>\n      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n    </tr>\n    <tr>\n      <th>237778</th>\n      <td>business</td>\n      <td>Подскажите какие риски бывают в семье среднест...</td>\n    </tr>\n  </tbody>\n</table>\n<p>237779 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.category.value_counts() * 100 / data.shape[0]","metadata":{"id":"90tXLjfsW-Aj","outputId":"5a41f708-1102-49c7-a38f-795783ccdd81","execution":{"iopub.status.busy":"2021-12-21T11:37:58.365878Z","iopub.execute_input":"2021-12-21T11:37:58.366196Z","iopub.status.idle":"2021-12-21T11:37:58.399499Z","shell.execute_reply.started":"2021-12-21T11:37:58.366157Z","shell.execute_reply":"2021-12-21T11:37:58.398560Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"law         29.793211\nrelax       22.016242\nbusiness    19.309527\nfood        18.367055\nlove        10.513965\nName: category, dtype: float64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Предобученные эмбеддинги\n[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \nВы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \nНиже мы сначала скачиваем, а потом распоковываем эмбеддинги.","metadata":{"id":"gfHbifWIW-Al"}},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n!gzip -d cc.ru.300.vec.gz","metadata":{"id":"PVhCzM3LW-Al","outputId":"7b800ec8-bcad-4859-f110-2ac5ddb07f0e","execution":{"iopub.status.busy":"2021-12-21T11:37:58.403347Z","iopub.execute_input":"2021-12-21T11:37:58.403743Z","iopub.status.idle":"2021-12-21T11:39:40.098231Z","shell.execute_reply.started":"2021-12-21T11:37:58.403693Z","shell.execute_reply":"2021-12-21T11:39:40.097399Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"--2021-12-21 11:37:59--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1306357571 (1.2G) [binary/octet-stream]\nSaving to: ‘cc.ru.300.vec.gz’\n\ncc.ru.300.vec.gz    100%[===================>]   1.22G  59.5MB/s    in 20s     \n\n2021-12-21 11:38:19 (62.2 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n\ngzip: cc.ru.300.vec already exists; do you wish to overwrite (y or n)? ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -l","metadata":{"id":"eJcT1qPZW-An","outputId":"6464b2a1-a04f-4112-a39d-4165ff7c4a79","execution":{"iopub.status.busy":"2021-12-21T11:39:40.099927Z","iopub.execute_input":"2021-12-21T11:39:40.100510Z","iopub.status.idle":"2021-12-21T11:39:40.768693Z","shell.execute_reply.started":"2021-12-21T11:39:40.100464Z","shell.execute_reply":"2021-12-21T11:39:40.767724Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"total 5761936\n---------- 1 root root        263 Dec 21 10:47 __notebook_source__.ipynb\n-rw-r--r-- 1 root root   28717126 Dec 21 10:49 answers_subsample.csv\n-rw-r--r-- 1 root root   28717126 Dec 21 11:37 answers_subsample.csv.1\n-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n-rw-r--r-- 1 root root 1306357571 Jan 18  2019 cc.ru.300.vec.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize, wordpunct_tokenize\nfrom tqdm import tqdm","metadata":{"id":"M0lwyZUFW-Ap","execution":{"iopub.status.busy":"2021-12-21T11:39:40.772053Z","iopub.execute_input":"2021-12-21T11:39:40.772298Z","iopub.status.idle":"2021-12-21T11:39:40.776326Z","shell.execute_reply.started":"2021-12-21T11:39:40.772266Z","shell.execute_reply":"2021-12-21T11:39:40.775478Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# потом можете добавить свою предобработку\n\ndef process_text(text):\n    \n    words = wordpunct_tokenize(text.lower())\n    \n    return words","metadata":{"id":"QQpX51Y4W-Aq","execution":{"iopub.status.busy":"2021-12-21T11:39:40.777969Z","iopub.execute_input":"2021-12-21T11:39:40.778514Z","iopub.status.idle":"2021-12-21T11:39:40.787485Z","shell.execute_reply.started":"2021-12-21T11:39:40.778476Z","shell.execute_reply":"2021-12-21T11:39:40.786722Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"word2freq = {}\nlengths = []\n\nfor text in tqdm(data.text):\n    \n    words = process_text(text)\n    \n    lengths.append(len(words))\n    \n    for word in words:\n        \n        if word in word2freq:\n            word2freq[word] += 1\n        else:\n            word2freq[word] = 1","metadata":{"id":"HyI2erCDW-Ar","outputId":"0e1fe01d-03f8-4073-b646-53f1a0834d90","execution":{"iopub.status.busy":"2021-12-21T11:39:40.789627Z","iopub.execute_input":"2021-12-21T11:39:40.790145Z","iopub.status.idle":"2021-12-21T11:39:43.857218Z","shell.execute_reply.started":"2021-12-21T11:39:40.790107Z","shell.execute_reply":"2021-12-21T11:39:43.856542Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 237779/237779 [00:03<00:00, 77860.98it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt","metadata":{"id":"FGzDm0ptW-At","execution":{"iopub.status.busy":"2021-12-21T11:39:43.858432Z","iopub.execute_input":"2021-12-21T11:39:43.858885Z","iopub.status.idle":"2021-12-21T11:39:43.934334Z","shell.execute_reply.started":"2021-12-21T11:39:43.858834Z","shell.execute_reply":"2021-12-21T11:39:43.933650Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16, 10))\nplt.title('Распределение длин слов в текстах')\nplt.xlabel('Длина предложения')\nplt.ylabel('Доля')\nsns.distplot(lengths)","metadata":{"id":"iZBR-aYDW-Av","outputId":"940b9a8b-91a9-4cdb-f79e-bcd0016e6958","execution":{"iopub.status.busy":"2021-12-21T11:39:43.935451Z","iopub.execute_input":"2021-12-21T11:39:43.936275Z","iopub.status.idle":"2021-12-21T11:39:45.134564Z","shell.execute_reply.started":"2021-12-21T11:39:43.936231Z","shell.execute_reply":"2021-12-21T11:39:45.133861Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n  warnings.warn(msg, FutureWarning)\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:title={'center':'Распределение длин слов в текстах'}, xlabel='Длина предложения', ylabel='Доля'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"upper_threshold = 32\nlower_threshold = 3\n\ncorrect_percent = len([sent_len for sent_len in lengths \n                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n\n'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)","metadata":{"id":"OBzmPqXIW-Aw","outputId":"e4430b5f-2d2a-4ac9-fc1a-fa194edd7645","execution":{"iopub.status.busy":"2021-12-21T11:39:45.135818Z","iopub.execute_input":"2021-12-21T11:39:45.136158Z","iopub.status.idle":"2021-12-21T11:39:45.168687Z","shell.execute_reply.started":"2021-12-21T11:39:45.136118Z","shell.execute_reply":"2021-12-21T11:39:45.168060Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"},"metadata":{}}]},{"cell_type":"code","source":"len(word2freq)","metadata":{"id":"GbSer_0bW-Ay","outputId":"d71619df-f68b-42a8-d851-3c909ceb6370","execution":{"iopub.status.busy":"2021-12-21T11:39:45.169809Z","iopub.execute_input":"2021-12-21T11:39:45.170124Z","iopub.status.idle":"2021-12-21T11:39:45.178176Z","shell.execute_reply.started":"2021-12-21T11:39:45.170088Z","shell.execute_reply":"2021-12-21T11:39:45.177474Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"152179"},"metadata":{}}]},{"cell_type":"code","source":"'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))","metadata":{"id":"szg6XD3EW-Az","outputId":"f41121aa-cbb5-426b-b7bb-8f21b1822bd0","execution":{"iopub.status.busy":"2021-12-21T11:39:45.179406Z","iopub.execute_input":"2021-12-21T11:39:45.180042Z","iopub.status.idle":"2021-12-21T11:39:45.220238Z","shell.execute_reply.started":"2021-12-21T11:39:45.180004Z","shell.execute_reply":"2021-12-21T11:39:45.219552Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'114332 слов, которые встречались 3 и менее раз'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Читаем файл с эмбеддингами\n### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\nПоэтому прочитаем только те слова, которые мы знаем","metadata":{"id":"bZbOg0FqW-A1"}},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"T1Yx_qr-W-A2","execution":{"iopub.status.busy":"2021-12-21T11:39:45.221218Z","iopub.execute_input":"2021-12-21T11:39:45.221451Z","iopub.status.idle":"2021-12-21T11:39:45.225540Z","shell.execute_reply.started":"2021-12-21T11:39:45.221418Z","shell.execute_reply":"2021-12-21T11:39:45.224556Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"word2index = {'PAD': 0}\nvectors = []\n    \nword2vec_file = open('cc.ru.300.vec')\n    \nn_words, embedding_dim = word2vec_file.readline().split()\nn_words, embedding_dim = int(n_words), int(embedding_dim)\n\n# Zero vector for PAD\nvectors.append(np.zeros((1, embedding_dim)))\n\nprogress_bar = tqdm(desc='Read word2vec', total=n_words)\n\nwhile True:\n\n    line = word2vec_file.readline().strip()\n\n    if not line:\n        break\n        \n    current_parts = line.split()\n\n    current_word = ' '.join(current_parts[:-embedding_dim])\n\n    if current_word in word2freq:\n\n        word2index[current_word] = len(word2index)\n\n        current_vectors = current_parts[-embedding_dim:]\n        current_vectors = np.array(list(map(float, current_vectors)))\n        current_vectors = np.expand_dims(current_vectors, 0)\n\n        vectors.append(current_vectors)\n\n    progress_bar.update(1)\n\nprogress_bar.close()\n\nword2vec_file.close()\n\nvectors = np.concatenate(vectors)","metadata":{"id":"BLEgfnaWW-A4","outputId":"05846f70-6229-4df2-bcd5-68cc08e0d010","execution":{"iopub.status.busy":"2021-12-21T11:39:45.227001Z","iopub.execute_input":"2021-12-21T11:39:45.227465Z","iopub.status.idle":"2021-12-21T11:40:57.178542Z","shell.execute_reply.started":"2021-12-21T11:39:45.227428Z","shell.execute_reply":"2021-12-21T11:40:57.177723Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Read word2vec: 100%|██████████| 2000000/2000000 [01:11<00:00, 27985.65it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(word2index)","metadata":{"id":"AYJMzgpnW-A7","outputId":"4fec5db6-fca6-42a2-93da-be988702d797","execution":{"iopub.status.busy":"2021-12-21T11:40:57.181084Z","iopub.execute_input":"2021-12-21T11:40:57.181381Z","iopub.status.idle":"2021-12-21T11:40:57.190339Z","shell.execute_reply.started":"2021-12-21T11:40:57.181349Z","shell.execute_reply":"2021-12-21T11:40:57.189533Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"117619"},"metadata":{}}]},{"cell_type":"code","source":"unk_words = [word for word in word2freq if word not in word2index]\nunk_counts = [word2freq[word] for word in unk_words]\nn_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n\nsub_sample_unk_words = {word: word2freq[word] for word in unk_words}\nsorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n\nprint('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\nprint('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\nprint('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\nprint()\nprint('Топ 5 невошедших слов:')\n\nfor i in range(5):\n    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])","metadata":{"id":"KE06fafiW-A8","outputId":"d6c87428-4474-4275-f300-d246364d7865","execution":{"iopub.status.busy":"2021-12-21T11:40:57.191775Z","iopub.execute_input":"2021-12-21T11:40:57.192233Z","iopub.status.idle":"2021-12-21T11:40:57.289027Z","shell.execute_reply.started":"2021-12-21T11:40:57.192196Z","shell.execute_reply":"2021-12-21T11:40:57.288270Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Мы не знаем 2.50 % слов в датасете\nКоличество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\nВ среднем каждое встречается 1.98 раз\n\nТоп 5 невошедших слов:\n??? с количеством вхождениий - 3641\n?? с количеством вхождениий - 2448\n!!! с количеством вхождениий - 2214\n?) с количеством вхождениий - 2069\n\"? с количеством вхождениий - 1429\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Потеря 2.5 % слов в датасете\nЭта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой.","metadata":{"id":"GFPNApUjW-A9"}},{"cell_type":"code","source":"import torch","metadata":{"id":"_fo1fB6JW-A-","execution":{"iopub.status.busy":"2021-12-21T11:40:57.291714Z","iopub.execute_input":"2021-12-21T11:40:57.291907Z","iopub.status.idle":"2021-12-21T11:40:58.644281Z","shell.execute_reply.started":"2021-12-21T11:40:57.291883Z","shell.execute_reply":"2021-12-21T11:40:58.643316Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"pEKAjCg3W-BA"}},{"cell_type":"code","source":"x = torch.rand(128, 64, 1024)","metadata":{"id":"D19pDyQBW-BA","execution":{"iopub.status.busy":"2021-12-21T11:40:58.649382Z","iopub.execute_input":"2021-12-21T11:40:58.649842Z","iopub.status.idle":"2021-12-21T11:40:58.834087Z","shell.execute_reply.started":"2021-12-21T11:40:58.649801Z","shell.execute_reply":"2021-12-21T11:40:58.832997Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512, batch_first=True)","metadata":{"id":"Yxsxr7edW-BB","execution":{"iopub.status.busy":"2021-12-21T11:40:58.835504Z","iopub.execute_input":"2021-12-21T11:40:58.836133Z","iopub.status.idle":"2021-12-21T11:40:58.949489Z","shell.execute_reply.started":"2021-12-21T11:40:58.836090Z","shell.execute_reply":"2021-12-21T11:40:58.948745Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm(x)","metadata":{"id":"TZy0lKr2W-BC","outputId":"4556ff61-4bd7-4ba5-da18-a26410a64d25","execution":{"iopub.status.busy":"2021-12-21T11:40:58.950623Z","iopub.execute_input":"2021-12-21T11:40:58.954109Z","iopub.status.idle":"2021-12-21T11:41:02.667251Z","shell.execute_reply.started":"2021-12-21T11:40:58.954068Z","shell.execute_reply":"2021-12-21T11:41:02.666477Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"424 ms ± 12.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# А что GPU?","metadata":{"id":"s611e34SW-BE"}},{"cell_type":"code","source":"print('Доступна ли видеокарта:', torch.cuda.is_available())\nprint('Если недоступна, поменяйте runtime, если в колабе')","metadata":{"id":"xjFlWdgtW-BE","outputId":"93205b98-fd2b-4bea-a93f-5544f82c5a2c","execution":{"iopub.status.busy":"2021-12-21T11:41:02.672832Z","iopub.execute_input":"2021-12-21T11:41:02.673195Z","iopub.status.idle":"2021-12-21T11:41:02.726101Z","shell.execute_reply.started":"2021-12-21T11:41:02.673151Z","shell.execute_reply":"2021-12-21T11:41:02.725361Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Доступна ли видеокарта: True\nЕсли недоступна, поменяйте runtime, если в колабе\n","output_type":"stream"}]},{"cell_type":"code","source":"# универсальных способ задать device\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать","metadata":{"id":"jaMMD5CDW-BG","execution":{"iopub.status.busy":"2021-12-21T11:41:02.727747Z","iopub.execute_input":"2021-12-21T11:41:02.728293Z","iopub.status.idle":"2021-12-21T11:41:02.737847Z","shell.execute_reply.started":"2021-12-21T11:41:02.728254Z","shell.execute_reply":"2021-12-21T11:41:02.737029Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# перенесли x на gpu\nx_gpu = x.to(device)","metadata":{"id":"GeQCiSYdW-BH","execution":{"iopub.status.busy":"2021-12-21T11:41:02.740930Z","iopub.execute_input":"2021-12-21T11:41:02.741179Z","iopub.status.idle":"2021-12-21T11:41:04.877140Z","shell.execute_reply.started":"2021-12-21T11:41:02.741154Z","shell.execute_reply":"2021-12-21T11:41:04.876285Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# зададим lstm на gpu\nlstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\nlstm_gpu = lstm_gpu.to(device)","metadata":{"id":"S_qUdMcbW-BJ","execution":{"iopub.status.busy":"2021-12-21T11:41:04.878714Z","iopub.execute_input":"2021-12-21T11:41:04.879021Z","iopub.status.idle":"2021-12-21T11:41:05.503078Z","shell.execute_reply.started":"2021-12-21T11:41:04.878979Z","shell.execute_reply":"2021-12-21T11:41:05.502318Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"%%timeit\n\npred = lstm_gpu(x_gpu)","metadata":{"id":"hSUQmRgtW-BK","outputId":"44da2f5b-6421-44d9-829b-499212280ee1","execution":{"iopub.status.busy":"2021-12-21T11:41:05.504424Z","iopub.execute_input":"2021-12-21T11:41:05.504701Z","iopub.status.idle":"2021-12-21T11:41:13.499210Z","shell.execute_reply.started":"2021-12-21T11:41:05.504652Z","shell.execute_reply":"2021-12-21T11:41:13.498362Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"10.2 ms ± 14.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз","metadata":{"id":"gPvqNWkQW-BM"}},{"cell_type":"code","source":"# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n# справедлива и обратная ситуация\n\n# выскочит ошибка\n# посмотрите на нее, возможно, вы еще встретитесь\n# pred = lstm_gpu(x)","metadata":{"id":"FaPKGO5aW-BN","execution":{"iopub.status.busy":"2021-12-21T11:41:13.500540Z","iopub.execute_input":"2021-12-21T11:41:13.500824Z","iopub.status.idle":"2021-12-21T11:41:13.506365Z","shell.execute_reply.started":"2021-12-21T11:41:13.500786Z","shell.execute_reply":"2021-12-21T11:41:13.504338Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# Важные и не очень интуитивные моменты про LSTM и CNN в торче","metadata":{"id":"9NX5HHDOW-BO"}},{"cell_type":"markdown","source":"По умолчанию LSTM принимает данные с такой размерностью:\n```python\n(seq_len, batch, input_size)\n```\nСделано это с целью оптимизации на более низком уровне.  \nМы оперируем такими объектами:\n```python\n(batch, seq_len, input_size)\n```\nЧтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\nлибо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)","metadata":{"id":"zKr22rklW-BP"}},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"Bny8SvCgW-BQ"}},{"cell_type":"code","source":"# первый способ\nlstm = torch.nn.LSTM(1024, 512, batch_first=True)\n\npred, mem = lstm(x)","metadata":{"id":"vc-bLok2W-BQ","execution":{"iopub.status.busy":"2021-12-21T11:41:13.508583Z","iopub.execute_input":"2021-12-21T11:41:13.509238Z","iopub.status.idle":"2021-12-21T11:41:14.014668Z","shell.execute_reply.started":"2021-12-21T11:41:13.509200Z","shell.execute_reply":"2021-12-21T11:41:14.013751Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"id":"OHpit-1tW-BR","outputId":"e33f0f23-f029-4e7b-b1ff-d3b12276db82","execution":{"iopub.status.busy":"2021-12-21T11:41:14.015913Z","iopub.execute_input":"2021-12-21T11:41:14.016305Z","iopub.status.idle":"2021-12-21T11:41:14.022629Z","shell.execute_reply.started":"2021-12-21T11:41:14.016268Z","shell.execute_reply":"2021-12-21T11:41:14.021876Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 64, 512])"},"metadata":{}}]},{"cell_type":"code","source":"lstm = torch.nn.LSTM(1024, 512)\n\n# меняем размерность batch и seq_len местами\nx_transposed = x.transpose(0, 1)\npred_transposed, mem = lstm(x_transposed)","metadata":{"id":"ru_WzGSJW-BS","execution":{"iopub.status.busy":"2021-12-21T11:41:14.023879Z","iopub.execute_input":"2021-12-21T11:41:14.024636Z","iopub.status.idle":"2021-12-21T11:41:14.580299Z","shell.execute_reply.started":"2021-12-21T11:41:14.024598Z","shell.execute_reply":"2021-12-21T11:41:14.579194Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# у нас все еще осталась размерность (seq_len, batch, input_size)\npred_transposed.shape","metadata":{"id":"NHdBavTWW-BT","outputId":"ba454a8b-fec7-402f-a7a1-c4f9f9556e6d","execution":{"iopub.status.busy":"2021-12-21T11:41:14.581451Z","iopub.execute_input":"2021-12-21T11:41:14.582126Z","iopub.status.idle":"2021-12-21T11:41:14.587495Z","shell.execute_reply.started":"2021-12-21T11:41:14.582085Z","shell.execute_reply":"2021-12-21T11:41:14.586598Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 128, 512])"},"metadata":{}}]},{"cell_type":"code","source":"# просто транспонируем еще раз\npred = pred_transposed.transpose(0, 1)\npred.shape","metadata":{"id":"Rcxv55j7W-BV","outputId":"f560450f-75bf-4397-d9f0-f88e3d06705c","execution":{"iopub.status.busy":"2021-12-21T11:41:14.588617Z","iopub.execute_input":"2021-12-21T11:41:14.589288Z","iopub.status.idle":"2021-12-21T11:41:14.601515Z","shell.execute_reply.started":"2021-12-21T11:41:14.589249Z","shell.execute_reply":"2021-12-21T11:41:14.600655Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 64, 512])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Conv1d & MaxPool1d\nПримерно такая же ситуация происходит со сверточными слоями и пулингами.  \n1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \nОжидается такая размерность:\n```python\n(batch, input_size, seq_len)\n```\nМы все еще хоти подавать такую размерность:\n```python\n(batch, seq_len, input_size)\n```\nВ случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля).","metadata":{"id":"PmJt6cqkW-BW"}},{"cell_type":"code","source":"x.shape","metadata":{"id":"TyM8Xl24W-BX","outputId":"2a5512ca-bc14-43f1-804b-e71df3a7ad7e","execution":{"iopub.status.busy":"2021-12-21T11:41:14.602818Z","iopub.execute_input":"2021-12-21T11:41:14.603191Z","iopub.status.idle":"2021-12-21T11:41:14.612488Z","shell.execute_reply.started":"2021-12-21T11:41:14.603089Z","shell.execute_reply":"2021-12-21T11:41:14.611370Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 64, 1024])"},"metadata":{}}]},{"cell_type":"markdown","source":"- 128 - размер батча\n- 64 - количество слов\n- 1024 - эмбеддинг слова","metadata":{"id":"grPNMjEZW-BY"}},{"cell_type":"code","source":"# in_channels - размер входных эмбеддингов\n# out_channels - количество/какой размер эмбеддингов мы хотим получить\n# kernel_size - размер окна/н-граммы\ncnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)","metadata":{"id":"btJ-ApiOW-BY","execution":{"iopub.status.busy":"2021-12-21T11:41:14.613639Z","iopub.execute_input":"2021-12-21T11:41:14.614245Z","iopub.status.idle":"2021-12-21T11:41:14.633490Z","shell.execute_reply.started":"2021-12-21T11:41:14.614195Z","shell.execute_reply":"2021-12-21T11:41:14.632901Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# выпадет ошибка, посмотрите какая\n# pred = cnn(x)","metadata":{"id":"QIYff7YyW-Bb","execution":{"iopub.status.busy":"2021-12-21T11:41:14.634863Z","iopub.execute_input":"2021-12-21T11:41:14.635144Z","iopub.status.idle":"2021-12-21T11:41:14.639987Z","shell.execute_reply.started":"2021-12-21T11:41:14.635110Z","shell.execute_reply":"2021-12-21T11:41:14.639070Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"x_transposed = x.transpose(1, 2)\nx_transposed.shape\n# перевели в (batch, input_size, seq_len)","metadata":{"id":"7tVn6YKLW-Bd","outputId":"7a1a5f4c-b44f-4ed6-f90c-a9d00f78dfe6","execution":{"iopub.status.busy":"2021-12-21T11:41:14.643115Z","iopub.execute_input":"2021-12-21T11:41:14.643647Z","iopub.status.idle":"2021-12-21T11:41:14.650572Z","shell.execute_reply.started":"2021-12-21T11:41:14.643572Z","shell.execute_reply":"2021-12-21T11:41:14.649833Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 1024, 64])"},"metadata":{}}]},{"cell_type":"code","source":"pred_transposed = cnn(x_transposed)\npred_transposed.shape\n# осталась разрмерность (batch, output_size, seq_len)","metadata":{"id":"2N4w6-iWW-Be","outputId":"bf29af13-5bd4-4882-f60f-b01575b100e8","execution":{"iopub.status.busy":"2021-12-21T11:41:14.651750Z","iopub.execute_input":"2021-12-21T11:41:14.652238Z","iopub.status.idle":"2021-12-21T11:41:14.927881Z","shell.execute_reply.started":"2021-12-21T11:41:14.652201Z","shell.execute_reply":"2021-12-21T11:41:14.927019Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 512, 62])"},"metadata":{}}]},{"cell_type":"code","source":"# переведем обратно в (batch, seq_len, input_size)\npred = pred_transposed.transpose(1, 2)\npred.shape","metadata":{"id":"7-C3_phaW-Bf","outputId":"2ce7a78f-5492-404a-aeb5-2911386734d4","execution":{"iopub.status.busy":"2021-12-21T11:41:14.929261Z","iopub.execute_input":"2021-12-21T11:41:14.929593Z","iopub.status.idle":"2021-12-21T11:41:14.938073Z","shell.execute_reply.started":"2021-12-21T11:41:14.929555Z","shell.execute_reply":"2021-12-21T11:41:14.937243Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"torch.Size([128, 62, 512])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Подготовим данные в DataLoader","metadata":{"id":"stBQ3yhqW-Bi"}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader","metadata":{"id":"vPX_m5M4W-Bi","execution":{"iopub.status.busy":"2021-12-21T11:41:14.939706Z","iopub.execute_input":"2021-12-21T11:41:14.940354Z","iopub.status.idle":"2021-12-21T11:41:14.944612Z","shell.execute_reply.started":"2021-12-21T11:41:14.940315Z","shell.execute_reply":"2021-12-21T11:41:14.943798Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"'UNK' in word2index","metadata":{"id":"hV76BdN0W-Bj","outputId":"befb4dd0-0df1-4ada-fe1d-dae478226f35","execution":{"iopub.status.busy":"2021-12-21T11:41:14.946302Z","iopub.execute_input":"2021-12-21T11:41:14.946948Z","iopub.status.idle":"2021-12-21T11:41:14.954679Z","shell.execute_reply.started":"2021-12-21T11:41:14.946812Z","shell.execute_reply":"2021-12-21T11:41:14.953542Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"id":"INB_dPAnW-Bk","outputId":"8bb90efa-4c9c-4908-c872-393906ed8619","execution":{"iopub.status.busy":"2021-12-21T11:41:14.956017Z","iopub.execute_input":"2021-12-21T11:41:14.956286Z","iopub.status.idle":"2021-12-21T11:41:14.968572Z","shell.execute_reply.started":"2021-12-21T11:41:14.956252Z","shell.execute_reply":"2021-12-21T11:41:14.967910Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"   category                                               text\n0  business  Могут ли в россельхозбанке дать в залог норков...\n1       law  Может ли срочник перевестись на контракт после...\n2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n3  business  В чем смысл криптовалюты, какая от неё выгода ...\n4       law                 часть 1 статья 158 похитил телефон","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>business</td>\n      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>law</td>\n      <td>Может ли срочник перевестись на контракт после...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>business</td>\n      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>business</td>\n      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>law</td>\n      <td>часть 1 статья 158 похитил телефон</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Замапим категории в индексы","metadata":{"id":"1qv1mKAeW-Bl"}},{"cell_type":"code","source":"cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}","metadata":{"id":"iHeFzZe1W-Bl","execution":{"iopub.status.busy":"2021-12-21T11:41:14.969737Z","iopub.execute_input":"2021-12-21T11:41:14.970237Z","iopub.status.idle":"2021-12-21T11:41:14.995054Z","shell.execute_reply.started":"2021-12-21T11:41:14.970199Z","shell.execute_reply":"2021-12-21T11:41:14.994144Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"cat_mapper","metadata":{"id":"X3x9QhXYW-Bn","outputId":"0a4dff58-d739-4847-f818-c3e0d321e78a","execution":{"iopub.status.busy":"2021-12-21T11:41:14.997320Z","iopub.execute_input":"2021-12-21T11:41:14.997819Z","iopub.status.idle":"2021-12-21T11:41:15.003710Z","shell.execute_reply.started":"2021-12-21T11:41:14.997776Z","shell.execute_reply":"2021-12-21T11:41:15.002892Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"},"metadata":{}}]},{"cell_type":"code","source":"data.category = data.category.map(cat_mapper)","metadata":{"id":"ef--8SWbW-Bo","execution":{"iopub.status.busy":"2021-12-21T11:41:15.006405Z","iopub.execute_input":"2021-12-21T11:41:15.006761Z","iopub.status.idle":"2021-12-21T11:41:15.034277Z","shell.execute_reply.started":"2021-12-21T11:41:15.006724Z","shell.execute_reply":"2021-12-21T11:41:15.033564Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Читалка данных","metadata":{"id":"vc48ALg_W-Bp"}},{"cell_type":"markdown","source":"## Что происходит ниже\n1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n1. Загружаем данные:\n    1. Проходимся по датасету\n    1. Предобрабатываем каждый текст в датасете\n    1. Индексируем его\n    1. Паддим до нужной длины\n1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n","metadata":{"id":"WFIQEv6nvE4c"}},{"cell_type":"code","source":"class WordData(Dataset):\n    \n    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n        \n        super().__init__()\n        \n        self.x_data = []\n        self.y_data = y_data\n        \n        self.word2index = word2index\n        self.sequence_length = sequence_length\n        \n        self.pad_token = pad_token\n        self.pad_index = self.word2index[self.pad_token]\n        \n        self.load(x_data, verbose=verbose)\n        \n    @staticmethod\n    def process_text(text):\n        \n        # Место для вашей предобработки\n        \n        words = wordpunct_tokenize(text.lower())\n        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n        return words\n        \n    def load(self, data, verbose=True):\n        \n        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n        \n        for text in data_iterator:\n            \n            words = self.process_text(text)\n            \n            indexed_words = self.indexing(words)\n            \n            self.x_data.append(indexed_words)\n    \n    def indexing(self, tokenized_text):\n\n        # здесь мы не используем токен UNK, потому что мы его специально не учили\n        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n        # поэтому просто выбрасываем наши неизветсные слова\n        \n        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n    \n    def padding(self, sequence):\n        \n        # Ограничить длину self.sequence_length\n        # если длина меньше максимально - западить\n        if len(sequence)< self.sequence_length:\n          add_pad = self.sequence_length - len(sequence)\n          return sequence+[self.pad_index]*add_pad\n        else:\n          return sequence[:self.sequence_length]\n    \n    def __len__(self):\n        \n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        \n        x = self.x_data[idx]\n        x = self.padding(x)\n        x = torch.Tensor(x).long()\n        \n        y = self.y_data[idx]\n        \n        return x, y","metadata":{"id":"ZkX8SC_sW-Bp","execution":{"iopub.status.busy":"2021-12-21T11:41:15.035526Z","iopub.execute_input":"2021-12-21T11:41:15.036283Z","iopub.status.idle":"2021-12-21T11:41:15.048609Z","shell.execute_reply.started":"2021-12-21T11:41:15.036238Z","shell.execute_reply":"2021-12-21T11:41:15.047884Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score","metadata":{"id":"R3WW8V9lyLm0","execution":{"iopub.status.busy":"2021-12-21T11:41:15.049643Z","iopub.execute_input":"2021-12-21T11:41:15.050268Z","iopub.status.idle":"2021-12-21T11:41:15.061384Z","shell.execute_reply.started":"2021-12-21T11:41:15.050221Z","shell.execute_reply":"2021-12-21T11:41:15.060692Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n\ntrain_dataset = WordData(list(x_train), list(y_train), word2index)\ntrain_loader = DataLoader(train_dataset, batch_size=64)\n\nvalidation_dataset = WordData(list(x_validation), list(y_validation), word2index)\nvalidation_loader = DataLoader(validation_dataset, batch_size=64)","metadata":{"id":"Lnc2nD8gW-Br","outputId":"d72654f9-7a85-49a6-e0c2-429b5db04c4e","execution":{"iopub.status.busy":"2021-12-21T11:41:15.063648Z","iopub.execute_input":"2021-12-21T11:41:15.064383Z","iopub.status.idle":"2021-12-21T11:41:18.431949Z","shell.execute_reply.started":"2021-12-21T11:41:15.064358Z","shell.execute_reply":"2021-12-21T11:41:18.431102Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stderr","text":"Loading data: 100%|██████████| 214001/214001 [00:02<00:00, 72305.55it/s]\nLoading data: 100%|██████████| 23778/23778 [00:00<00:00, 83598.77it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"for x, y in train_loader:\n    break","metadata":{"id":"dGeftxdgW-Br","execution":{"iopub.status.busy":"2021-12-21T11:41:18.433475Z","iopub.execute_input":"2021-12-21T11:41:18.433771Z","iopub.status.idle":"2021-12-21T11:41:18.444414Z","shell.execute_reply.started":"2021-12-21T11:41:18.433732Z","shell.execute_reply":"2021-12-21T11:41:18.443691Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"x","metadata":{"id":"nNkGQffBW-Bs","outputId":"77e1ecb5-4bdc-414d-fb89-b7650ed25fba","execution":{"iopub.status.busy":"2021-12-21T11:41:18.445526Z","iopub.execute_input":"2021-12-21T11:41:18.446811Z","iopub.status.idle":"2021-12-21T11:41:18.455303Z","shell.execute_reply.started":"2021-12-21T11:41:18.446771Z","shell.execute_reply":"2021-12-21T11:41:18.454438Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"tensor([[  153,   137,  4758,  ...,     0,     0,     0],\n        [    4,   256, 13259,  ...,     0,     0,     0],\n        [   24, 26828,    10,  ...,     0,     0,     0],\n        ...,\n        [  593,  9226,  3771,  ...,     0,     0,     0],\n        [  115,    56,   342,  ...,     0,     0,     0],\n        [   19,   129,  3771,  ...,     0,     0,     0]])"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"id":"fxUk4nGcW-Bt","outputId":"bae977fd-25ef-4fd7-c451-402e8ea287a4","execution":{"iopub.status.busy":"2021-12-21T11:41:18.457148Z","iopub.execute_input":"2021-12-21T11:41:18.457646Z","iopub.status.idle":"2021-12-21T11:41:18.463938Z","shell.execute_reply.started":"2021-12-21T11:41:18.457609Z","shell.execute_reply":"2021-12-21T11:41:18.463205Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"tensor([1, 1, 3, 0, 1, 1, 2, 1, 0, 2, 2, 0, 4, 0, 0, 0, 0, 4, 4, 4, 4, 3, 4, 0,\n        3, 3, 3, 3, 0, 2, 3, 2, 2, 1, 2, 0, 2, 2, 4, 3, 1, 4, 4, 1, 0, 0, 0, 1,\n        0, 1, 0, 3, 3, 1, 0, 1, 4, 0, 3, 3, 3, 4, 3, 4])"},"metadata":{}}]},{"cell_type":"markdown","source":"# Обучить нейронку","metadata":{"id":"Zy0dkkTIW-Bw"}},{"cell_type":"code","source":"from math import sqrt\n\nclass model_with_att(torch.nn.Module):\n  def __init__(self, matrix_w, n): #n - количетсво категорий\n        \n        super().__init__()\n\n        self.n = n\n        \n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        self.LSTM = torch.nn.LSTM(300, 256, \n                                  num_layers=2, bidirectional=True, dropout=0.1,\n                                  batch_first=True)\n        \n        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=3, stride=1)\n        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=4, stride=1)\n        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=5, stride=1)\n\n        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n        self.relu = torch.nn.ReLU()\n        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n\n        \n  def forward(self, x):\n      x_emb = self.emb_layer(x) #примените эмбеддинги\n      # транспонируйте тензор для лстм как было описано выше\n      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n      # транспонируйте обратно\n\n      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n      x_k = self.k_proj(x)\n      x_v = self.v_proj(x)\n\n      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_q.size(-1))\n      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n      attention_vectors = torch.bmm(att_dist, x_v)\n\n      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n\n      x_cnn3 = self.cnn_3gr(x_att)\n      x_cnn4 = self.cnn_4gr(x_att)\n      x_cnn5 = self.cnn_5gr(x_att)\n\n      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n      sc, _ = x_cnn4.max(dim= -1,)\n      thr, _ = x_cnn5.max(dim= -1,)\n      \n      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n      \n      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n      x = self.relu(x)    \n      x = self.linear_2(x)\n    \n      return x","metadata":{"id":"3wwkxZm1vE43","execution":{"iopub.status.busy":"2021-12-21T11:41:18.465493Z","iopub.execute_input":"2021-12-21T11:41:18.466079Z","iopub.status.idle":"2021-12-21T11:41:18.482535Z","shell.execute_reply.started":"2021-12-21T11:41:18.466042Z","shell.execute_reply":"2021-12-21T11:41:18.481520Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"n_classes = data.category.unique().shape[0]","metadata":{"id":"jFbyUXLE0WPv","execution":{"iopub.status.busy":"2021-12-21T11:41:18.483560Z","iopub.execute_input":"2021-12-21T11:41:18.485799Z","iopub.status.idle":"2021-12-21T11:41:18.498057Z","shell.execute_reply.started":"2021-12-21T11:41:18.485762Z","shell.execute_reply":"2021-12-21T11:41:18.497281Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"model = model_with_att(vectors, n_classes)","metadata":{"id":"OZgh4ONx0HvT","execution":{"iopub.status.busy":"2021-12-21T11:41:18.500634Z","iopub.execute_input":"2021-12-21T11:41:18.500905Z","iopub.status.idle":"2021-12-21T11:41:18.629460Z","shell.execute_reply.started":"2021-12-21T11:41:18.500872Z","shell.execute_reply":"2021-12-21T11:41:18.628719Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model #если сделать batch_first=True, то можно не транспонировать батчи","metadata":{"id":"CNO6VSbJgQ36","outputId":"409a1cc5-8448-4a0e-ec43-77d8d6f79683","execution":{"iopub.status.busy":"2021-12-21T11:41:18.630715Z","iopub.execute_input":"2021-12-21T11:41:18.631058Z","iopub.status.idle":"2021-12-21T11:41:18.636887Z","shell.execute_reply.started":"2021-12-21T11:41:18.631019Z","shell.execute_reply":"2021-12-21T11:41:18.636142Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"model_with_att(\n  (emb_layer): Embedding(117619, 300)\n  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n  (att_soft): Softmax(dim=2)\n  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n  (relu): ReLU()\n  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"with torch.no_grad():\n    pred = model(x)","metadata":{"id":"E66MWNgM0QKM","execution":{"iopub.status.busy":"2021-12-21T11:41:18.638395Z","iopub.execute_input":"2021-12-21T11:41:18.638888Z","iopub.status.idle":"2021-12-21T11:41:18.829000Z","shell.execute_reply.started":"2021-12-21T11:41:18.638851Z","shell.execute_reply":"2021-12-21T11:41:18.828236Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"id":"ErboeQbv0dnC","execution":{"iopub.status.busy":"2021-12-21T11:41:18.830144Z","iopub.execute_input":"2021-12-21T11:41:18.830416Z","iopub.status.idle":"2021-12-21T11:41:18.835792Z","shell.execute_reply.started":"2021-12-21T11:41:18.830381Z","shell.execute_reply":"2021-12-21T11:41:18.835057Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 5])"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"id":"bL6zIZSt0h9W","execution":{"iopub.status.busy":"2021-12-21T11:41:18.836900Z","iopub.execute_input":"2021-12-21T11:41:18.837588Z","iopub.status.idle":"2021-12-21T11:41:18.843848Z","shell.execute_reply.started":"2021-12-21T11:41:18.837551Z","shell.execute_reply":"2021-12-21T11:41:18.843089Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"id":"Vsxw4M2m0m2B","execution":{"iopub.status.busy":"2021-12-21T11:41:18.845144Z","iopub.execute_input":"2021-12-21T11:41:18.845623Z","iopub.status.idle":"2021-12-21T11:41:18.898037Z","shell.execute_reply.started":"2021-12-21T11:41:18.845587Z","shell.execute_reply":"2021-12-21T11:41:18.897389Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"id":"7rUTc0l60pV9","outputId":"ea81b9b3-b1d3-4122-869b-da0592397d76","execution":{"iopub.status.busy":"2021-12-21T11:41:18.899244Z","iopub.execute_input":"2021-12-21T11:41:18.899638Z","iopub.status.idle":"2021-12-21T11:47:58.006862Z","shell.execute_reply.started":"2021-12-21T11:41:18.899602Z","shell.execute_reply":"2021-12-21T11:47:58.006067Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 214001/214001 [01:21<00:00, 2618.48it/s, train_loss=0.481]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.566, test - 0.463\nF1 test - 0.832\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 214001/214001 [01:16<00:00, 2793.13it/s, train_loss=0.446]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.454, test - 0.447\nF1 test - 0.838\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 214001/214001 [01:16<00:00, 2795.71it/s, train_loss=0.423]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.427, test - 0.429\nF1 test - 0.844\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 214001/214001 [01:16<00:00, 2789.88it/s, train_loss=0.401]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.405, test - 0.428\nF1 test - 0.846\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 214001/214001 [01:16<00:00, 2794.87it/s, train_loss=0.377]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.382, test - 0.438\nF1 test - 0.846\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо","metadata":{"id":"1TMaPbh3oWwc"}},{"cell_type":"code","source":"for instance in list(tqdm._instances): \n    tqdm._decr_instances(instance)","metadata":{"id":"_aPjTQcR0vm2","outputId":"03d584f8-2f8c-4e0b-ae8e-7112f6624275","execution":{"iopub.status.busy":"2021-12-21T11:49:01.927254Z","iopub.execute_input":"2021-12-21T11:49:01.927808Z","iopub.status.idle":"2021-12-21T11:49:01.932655Z","shell.execute_reply.started":"2021-12-21T11:49:01.927766Z","shell.execute_reply":"2021-12-21T11:49:01.931404Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"# Оценка\n1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов ","metadata":{}},{"cell_type":"markdown","source":"# Что я делал\n\n1. Поигрался с оптимайзерами и их гиперпараметрами - не помогло\n2. Добавил дропаут - чуть-чуть стало лучше\n3. Пробовал менять предобработку - стало хуже (лемматизация)\n4. Поигрался с функциями акттивации, Parametric ReLU вроде работает лучше P.S. увидел сообщение в чате, согласен что немного тупо надеяться на функцию активации при шумных данных","metadata":{}},{"cell_type":"code","source":"from math import sqrt\n\nclass model_improved(torch.nn.Module):\n  def __init__(self, matrix_w, n): #n - количетсво категорий\n        \n        super().__init__()\n\n        self.n = n\n        \n        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n\n        self.LSTM = torch.nn.LSTM(300, 256, \n                                  num_layers=2, bidirectional=True, dropout=0.1,\n                                  batch_first=True)\n        \n        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n\n        self.att_soft = torch.nn.Softmax(dim = 2)\n        \n        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=3, stride=1)\n        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=4, stride=1)\n        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=5, stride=1)\n\n        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n        self.relu = torch.nn.PReLU()\n        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n        self.dropout = torch.nn.Dropout(p=0.3)\n\n        \n  def forward(self, x):\n      x_emb = self.emb_layer(x) #примените эмбеддинги\n      # транспонируйте тензор для лстм как было описано выше\n      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n      # транспонируйте обратно\n\n      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n      x_k = self.k_proj(x)\n      x_v = self.v_proj(x)\n\n      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) / sqrt(x_q.size(-1))\n      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n      attention_vectors = torch.bmm(att_dist, x_v)\n\n      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n\n      x_cnn3 = self.cnn_3gr(x_att)\n      x_cnn4 = self.cnn_4gr(x_att)\n      x_cnn5 = self.cnn_5gr(x_att)\n\n      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n      sc, _ = x_cnn4.max(dim= -1,)\n      thr, _ = x_cnn5.max(dim= -1,)\n      \n      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n      \n      x =  self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n      x = self.dropout(self.relu(x))    \n      x = self.linear_2(x)\n    \n      return x","metadata":{"id":"e5BgHdtW2sO3","execution":{"iopub.status.busy":"2021-12-21T11:49:06.044806Z","iopub.execute_input":"2021-12-21T11:49:06.045309Z","iopub.status.idle":"2021-12-21T11:49:06.062156Z","shell.execute_reply.started":"2021-12-21T11:49:06.045266Z","shell.execute_reply":"2021-12-21T11:49:06.061405Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"model = model_improved(vectors, n_classes)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:49:06.977038Z","iopub.execute_input":"2021-12-21T11:49:06.977301Z","iopub.status.idle":"2021-12-21T11:49:07.106086Z","shell.execute_reply.started":"2021-12-21T11:49:06.977269Z","shell.execute_reply":"2021-12-21T11:49:07.105321Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters())\n\nmodel = model.to(device)\ncriterion = criterion.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:49:07.820994Z","iopub.execute_input":"2021-12-21T11:49:07.821585Z","iopub.status.idle":"2021-12-21T11:49:07.871369Z","shell.execute_reply.started":"2021-12-21T11:49:07.821542Z","shell.execute_reply":"2021-12-21T11:49:07.870683Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nlosses = []\nbest_test_loss = 10.\n\ntest_f1 = []\n\nfor n_epoch in range(epochs):\n    \n    train_losses = []\n    test_losses = []\n    test_targets = []\n    test_pred_class = []\n    \n    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n    \n    model.train()\n    \n    for x, y in train_loader:\n\n        x = x.to(device)\n        y = y.to(device)\n        \n        optimizer.zero_grad()\n        \n        pred = model(x)\n        loss = criterion(pred, y)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        train_losses.append(loss.item())\n        losses.append(loss.item())\n        \n        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n\n        progress_bar.update(x.shape[0])\n        \n    progress_bar.close()\n    \n    model.eval()\n    \n    for x, y in validation_loader:\n        \n        x = x.to(device)\n\n        with torch.no_grad():\n\n            pred = model(x)\n\n            pred = pred.cpu()\n\n            test_targets.append(y.numpy())\n            test_pred_class.append(np.argmax(pred, axis=1))\n\n            loss = criterion(pred, y)\n\n            test_losses.append(loss.item())\n        \n    mean_test_loss = np.mean(test_losses)\n\n    test_targets = np.concatenate(test_targets).squeeze()\n    test_pred_class = np.concatenate(test_pred_class).squeeze()\n\n    f1 = f1_score(test_targets, test_pred_class, average='micro')\n\n    test_f1.append(f1)\n    \n    print()\n    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n\n    print('F1 test - {:.3f}'.format(f1))\n        \n    # Early stopping:\n    if mean_test_loss < best_test_loss:\n        best_test_loss = mean_test_loss\n    else:\n        print('Early stopping')\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:49:08.618756Z","iopub.execute_input":"2021-12-21T11:49:08.619488Z","iopub.status.idle":"2021-12-21T11:55:36.864242Z","shell.execute_reply.started":"2021-12-21T11:49:08.619441Z","shell.execute_reply":"2021-12-21T11:55:36.863355Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 214001/214001 [01:15<00:00, 2839.73it/s, train_loss=0.486]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.563, test - 0.471\nF1 test - 0.828\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 214001/214001 [01:15<00:00, 2833.01it/s, train_loss=0.453]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.459, test - 0.454\nF1 test - 0.835\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 214001/214001 [01:15<00:00, 2832.46it/s, train_loss=0.428]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.432, test - 0.438\nF1 test - 0.841\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 214001/214001 [01:15<00:00, 2835.65it/s, train_loss=0.406]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.410, test - 0.427\nF1 test - 0.847\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 214001/214001 [01:15<00:00, 2829.84it/s, train_loss=0.382]\n","output_type":"stream"},{"name":"stdout","text":"\nLosses: train - 0.387, test - 0.439\nF1 test - 0.845\nEarly stopping\n","output_type":"stream"}]},{"cell_type":"markdown","source":"P.S. Решил запустить все еще раз, и видимо, мне попался какой-то очень крутой сид, т.к. на первой модели точность 0.846 и побороть ее на улучшенной модели не вышло. На предыдущих тестах с такими же параметрами модели было все позитивнее: 0.841, затем 0.842, чуть чуть, но улучшилось. Могу отправить скрины если надо, сохранял ровно на такой случай ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# BERT","metadata":{}},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:55:43.827202Z","iopub.execute_input":"2021-12-21T11:55:43.827469Z","iopub.status.idle":"2021-12-21T11:55:52.755785Z","shell.execute_reply.started":"2021-12-21T11:55:43.827437Z","shell.execute_reply":"2021-12-21T11:55:52.754907Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.12.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.46)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.8.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Наши данные","metadata":{}},{"cell_type":"code","source":"sentences = data.text.values\nlabels = data.category.values","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:55:54.420402Z","iopub.execute_input":"2021-12-21T11:55:54.420714Z","iopub.status.idle":"2021-12-21T11:55:54.426734Z","shell.execute_reply.started":"2021-12-21T11:55:54.420658Z","shell.execute_reply":"2021-12-21T11:55:54.425997Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"len(data.category.unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-21T11:56:51.580566Z","iopub.execute_input":"2021-12-21T11:56:51.580854Z","iopub.status.idle":"2021-12-21T11:56:51.588499Z","shell.execute_reply.started":"2021-12-21T11:56:51.580823Z","shell.execute_reply":"2021-12-21T11:56:51.587739Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Load the BERT tokenizer.\nprint('Loading BERT tokenizer...')\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:34:53.064131Z","iopub.execute_input":"2021-12-21T12:34:53.064416Z","iopub.status.idle":"2021-12-21T12:34:55.563216Z","shell.execute_reply.started":"2021-12-21T12:34:53.064382Z","shell.execute_reply":"2021-12-21T12:34:55.562482Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"Loading BERT tokenizer...\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print the original sentence.\nprint(' Original: ', sentences[0])\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(sentences[0]))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:34:55.609834Z","iopub.execute_input":"2021-12-21T12:34:55.610052Z","iopub.status.idle":"2021-12-21T12:34:55.619031Z","shell.execute_reply.started":"2021-12-21T12:34:55.610026Z","shell.execute_reply":"2021-12-21T12:34:55.616448Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":" Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\nTokenized:  ['могут', 'ли', 'в', 'рос', '##сель', '##хо', '##з', '##бан', '##ке', 'да', '##ть', 'в', 'зал', '##ог', 'но', '##рк', '##овых', 'ш', '##уб', 'пом', '##оги', '##те', 'по', '##жал', '##уи', '##ста']\nToken IDs:  [22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294]\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:34:56.613607Z","iopub.execute_input":"2021-12-21T12:34:56.615312Z","iopub.status.idle":"2021-12-21T12:34:56.620449Z","shell.execute_reply.started":"2021-12-21T12:34:56.615270Z","shell.execute_reply":"2021-12-21T12:34:56.619715Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# Tokenize all of the sentences and map the tokens to thier word IDs.\ninput_ids = []\n\n# For every sentence...\nfor sent in tqdm(sentences):\n    # `encode` will:\n    #   (1) Tokenize the sentence.\n    #   (2) Prepend the `[CLS]` token to the start.\n    #   (3) Append the `[SEP]` token to the end.\n    #   (4) Map tokens to their IDs.\n    encoded_sent = tokenizer.encode(\n                        sent,                      # Sentence to encode.\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n\n                        # This function also supports truncation and conversion\n                        # to pytorch tensors, but we need to do padding, so we\n                        # can't use these features :( .\n                        #max_length = 128,          # Truncate all sentences.\n                        #return_tensors = 'pt',     # Return pytorch tensors.\n                   )\n    \n    # Add the encoded sentence to the list.\n    input_ids.append(encoded_sent)\n\n# Print sentence 0, now as a list of IDs.\nprint('Original: ', sentences[0])\nprint('Token IDs:', input_ids[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:36:03.858394Z","iopub.execute_input":"2021-12-21T12:36:03.858787Z","iopub.status.idle":"2021-12-21T12:38:18.943797Z","shell.execute_reply.started":"2021-12-21T12:36:03.858741Z","shell.execute_reply":"2021-12-21T12:38:18.943061Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stderr","text":"100%|██████████| 237779/237779 [02:15<00:00, 1760.53it/s]","output_type":"stream"},{"name":"stdout","text":"Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\nToken IDs: [101, 22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294, 102]\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Max sentence length: ', max([len(sen) for sen in input_ids]))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:18.945604Z","iopub.execute_input":"2021-12-21T12:38:18.946397Z","iopub.status.idle":"2021-12-21T12:38:18.979083Z","shell.execute_reply.started":"2021-12-21T12:38:18.946359Z","shell.execute_reply":"2021-12-21T12:38:18.978346Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Max sentence length:  97\n","output_type":"stream"}]},{"cell_type":"code","source":"# We'll borrow the `pad_sequences` utility function to do this.\nfrom keras.preprocessing.sequence import pad_sequences\n\n# Set the maximum sequence length.\n# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n# maximum training sentence length of 47...\nMAX_LEN = 70\n\nprint('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n\nprint('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n\n# Pad our input tokens with value 0.\n# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n# as opposed to the beginning.\ninput_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n                          value=0, truncating=\"post\", padding=\"post\")\n\nprint('\\nDone.')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:18.980184Z","iopub.execute_input":"2021-12-21T12:38:18.980501Z","iopub.status.idle":"2021-12-21T12:38:21.210918Z","shell.execute_reply.started":"2021-12-21T12:38:18.980461Z","shell.execute_reply":"2021-12-21T12:38:21.210194Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"\nPadding/truncating all sentences to 70 values...\n\nPadding token: \"[PAD]\", ID: 0\n\nDone.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create attention masks\nattention_masks = []\n\n# For each sentence...\nfor sent in tqdm(input_ids):\n    \n    # Create the attention mask.\n    #   - If a token ID is 0, then it's padding, set the mask to 0.\n    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n    att_mask = [int(token_id > 0) for token_id in sent]\n    \n    # Store the attention mask for this sentence.\n    attention_masks.append(att_mask)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:21.212050Z","iopub.execute_input":"2021-12-21T12:38:21.214832Z","iopub.status.idle":"2021-12-21T12:38:37.661176Z","shell.execute_reply.started":"2021-12-21T12:38:21.214793Z","shell.execute_reply":"2021-12-21T12:38:37.660443Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stderr","text":"100%|██████████| 237779/237779 [00:16<00:00, 14505.64it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use train_test_split to split our data into train and validation sets for\n# training\nfrom sklearn.model_selection import train_test_split\n\n# Use 90% for training and 10% for validation.\ntrain_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n                                                            random_state=2018, test_size=0.1)\n# Do the same for the masks.\ntrain_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n                                             random_state=2018, test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:37.663697Z","iopub.execute_input":"2021-12-21T12:38:37.663980Z","iopub.status.idle":"2021-12-21T12:38:37.874264Z","shell.execute_reply.started":"2021-12-21T12:38:37.663942Z","shell.execute_reply":"2021-12-21T12:38:37.873290Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# Convert all inputs and labels into torch tensors, the required datatype \n# for our model.\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\n\ntrain_labels = torch.tensor(train_labels)\nvalidation_labels = torch.tensor(validation_labels)\n\ntrain_masks = torch.tensor(train_masks)\nvalidation_masks = torch.tensor(validation_masks)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:37.875558Z","iopub.execute_input":"2021-12-21T12:38:37.875844Z","iopub.status.idle":"2021-12-21T12:38:39.949086Z","shell.execute_reply.started":"2021-12-21T12:38:37.875804Z","shell.execute_reply":"2021-12-21T12:38:39.948282Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"markdown","source":"Поставим батч побольше, а то ну очень уж долго","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n# The DataLoader needs to know our batch size for training, so we specify it \n# here.\n# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n# 16 or 32.\n\nbatch_size = 64\n\n# Create the DataLoader for our training set.\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# Create the DataLoader for our validation set.\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:39.950357Z","iopub.execute_input":"2021-12-21T12:38:39.950617Z","iopub.status.idle":"2021-12-21T12:38:39.964166Z","shell.execute_reply.started":"2021-12-21T12:38:39.950583Z","shell.execute_reply":"2021-12-21T12:38:39.963507Z"},"trusted":true},"execution_count":146,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForSequenceClassification, AdamW, BertConfig\n\n# Load BertForSequenceClassification, the pretrained BERT model with a single \n# linear classification layer on top. \nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# Tell pytorch to run this model on the GPU.\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:39.965557Z","iopub.execute_input":"2021-12-21T12:38:39.966040Z","iopub.status.idle":"2021-12-21T12:38:42.769930Z","shell.execute_reply.started":"2021-12-21T12:38:39.966001Z","shell.execute_reply":"2021-12-21T12:38:42.768868Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=5, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"b = model.bert.pooler.dense.weight\nc = model.classifier.weight\nb = b.cpu().detach().numpy()\nc = c.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.190498Z","iopub.execute_input":"2021-12-21T14:14:46.190848Z","iopub.status.idle":"2021-12-21T14:14:46.196377Z","shell.execute_reply.started":"2021-12-21T14:14:46.190806Z","shell.execute_reply":"2021-12-21T14:14:46.195577Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# Get all of the model's parameters as a list of tuples.\nparams = list(model.named_parameters())\n\nprint('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n\nprint('==== Embedding Layer ====\\n')\n\nfor p in params[0:5]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\n\nfor p in params[5:21]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layer ====\\n')\n\nfor p in params[-4:]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.199775Z","iopub.execute_input":"2021-12-21T14:14:46.200296Z","iopub.status.idle":"2021-12-21T14:14:46.213014Z","shell.execute_reply.started":"2021-12-21T14:14:46.200260Z","shell.execute_reply":"2021-12-21T14:14:46.211565Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stdout","text":"The BERT model has 201 different named parameters.\n\n==== Embedding Layer ====\n\nbert.embeddings.word_embeddings.weight                  (105879, 768)\nbert.embeddings.position_embeddings.weight                (512, 768)\nbert.embeddings.token_type_embeddings.weight                (2, 768)\nbert.embeddings.LayerNorm.weight                              (768,)\nbert.embeddings.LayerNorm.bias                                (768,)\n\n==== First Transformer ====\n\nbert.encoder.layer.0.attention.self.query.weight          (768, 768)\nbert.encoder.layer.0.attention.self.query.bias                (768,)\nbert.encoder.layer.0.attention.self.key.weight            (768, 768)\nbert.encoder.layer.0.attention.self.key.bias                  (768,)\nbert.encoder.layer.0.attention.self.value.weight          (768, 768)\nbert.encoder.layer.0.attention.self.value.bias                (768,)\nbert.encoder.layer.0.attention.output.dense.weight        (768, 768)\nbert.encoder.layer.0.attention.output.dense.bias              (768,)\nbert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\nbert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\nbert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\nbert.encoder.layer.0.intermediate.dense.bias                 (3072,)\nbert.encoder.layer.0.output.dense.weight                 (768, 3072)\nbert.encoder.layer.0.output.dense.bias                        (768,)\nbert.encoder.layer.0.output.LayerNorm.weight                  (768,)\nbert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n\n==== Output Layer ====\n\nbert.pooler.dense.weight                                  (768, 768)\nbert.pooler.dense.bias                                        (768,)\nclassifier.weight                                           (5, 768)\nclassifier.bias                                                 (5,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n# I believe the 'W' stands for 'Weight Decay fix\"\noptimizer = AdamW(model.parameters(),\n                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.214596Z","iopub.execute_input":"2021-12-21T14:14:46.215502Z","iopub.status.idle":"2021-12-21T14:14:46.223826Z","shell.execute_reply.started":"2021-12-21T14:14:46.215464Z","shell.execute_reply":"2021-12-21T14:14:46.222981Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\n# Number of training epochs (authors recommend between 2 and 4)\nepochs = 4\n\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 100, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2021-12-21T14:14:46.224925Z","iopub.execute_input":"2021-12-21T14:14:46.226782Z","iopub.status.idle":"2021-12-21T14:14:46.232380Z","shell.execute_reply.started":"2021-12-21T14:14:46.226731Z","shell.execute_reply":"2021-12-21T14:14:46.231592Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"markdown","source":"Перепишем метрику, чтобы былл f score а не accuracy","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(pred_flat, labels_flat, average='micro')","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:42.814292Z","iopub.execute_input":"2021-12-21T12:38:42.815225Z","iopub.status.idle":"2021-12-21T12:38:42.823008Z","shell.execute_reply.started":"2021-12-21T12:38:42.815194Z","shell.execute_reply":"2021-12-21T12:38:42.822093Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:42.826326Z","iopub.execute_input":"2021-12-21T12:38:42.826582Z","iopub.status.idle":"2021-12-21T12:38:42.832270Z","shell.execute_reply.started":"2021-12-21T12:38:42.826554Z","shell.execute_reply":"2021-12-21T12:38:42.831436Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"import random\n\n# This training code is based on the `run_glue.py` script here:\n# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n# Store the average loss after each epoch so we can plot them.\nloss_values = []\n\n# For each epoch...\nfor epoch_i in range(0, epochs):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    \n    # Perform one full pass over the training set.\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    # Measure how long the training epoch takes.\n    t0 = time.time()\n\n    # Reset the total loss for this epoch.\n    total_loss = 0\n\n    # Put the model into training mode. Don't be mislead--the call to \n    # `train` just changes the *mode*, it doesn't *perform* the training.\n    # `dropout` and `batchnorm` layers behave differently during training\n    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n    model.train()\n\n    # For each batch of training data...\n    for step, batch in enumerate(train_dataloader):\n\n        # Progress update every 40 batches.\n        if step % 40 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n        # `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        # Always clear any previously calculated gradients before performing a\n        # backward pass. PyTorch doesn't do this automatically because \n        # accumulating the gradients is \"convenient while training RNNs\". \n        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n        model.zero_grad()        \n\n        # Perform a forward pass (evaluate the model on this training batch).\n        # This will return the loss (rather than the model output) because we\n        # have provided the `labels`.\n        # The documentation for this `model` function is here: \n        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n        outputs = model(b_input_ids, \n                    token_type_ids=None, \n                    attention_mask=b_input_mask, \n                    labels=b_labels)\n        \n        # The call to `model` always returns a tuple, so we need to pull the \n        # loss value out of the tuple.\n        loss = outputs[0]\n\n        # Accumulate the training loss over all of the batches so that we can\n        # calculate the average loss at the end. `loss` is a Tensor containing a\n        # single value; the `.item()` function just returns the Python value \n        # from the tensor.\n        total_loss += loss.item()\n\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n\n        # Clip the norm of the gradients to 1.0.\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters and take a step using the computed gradient.\n        # The optimizer dictates the \"update rule\"--how the parameters are\n        # modified based on their gradients, the learning rate, etc.\n        optimizer.step()\n\n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over the training data.\n    avg_train_loss = total_loss / len(train_dataloader)            \n    \n    # Store the loss value for plotting the learning curve.\n    loss_values.append(avg_train_loss)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n        \n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n    # Put the model in evaluation mode--the dropout layers behave differently\n    # during evaluation.\n    model.eval()\n\n    # Tracking variables \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n\n    # Evaluate data for one epoch\n    for batch in validation_dataloader:\n        \n        # Add batch to GPU\n        batch = tuple(t.to(device) for t in batch)\n        \n        # Unpack the inputs from our dataloader\n        b_input_ids, b_input_mask, b_labels = batch\n        \n        # Telling the model not to compute or store gradients, saving memory and\n        # speeding up validation\n        with torch.no_grad():        \n\n            # Forward pass, calculate logit predictions.\n            # This will return the logits rather than the loss because we have\n            # not provided labels.\n            # token_type_ids is the same as the \"segment ids\", which \n            # differentiates sentence 1 and 2 in 2-sentence tasks.\n            # The documentation for this `model` function is here: \n            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n            outputs = model(b_input_ids, \n                            token_type_ids=None, \n                            attention_mask=b_input_mask)\n        \n        # Get the \"logits\" output by the model. The \"logits\" are the output\n        # values prior to applying an activation function like the softmax.\n        logits = outputs[0]\n\n        # Move logits and labels to CPU\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        \n        # Calculate the accuracy for this batch of test sentences.\n        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n        \n        # Accumulate the total accuracy.\n        eval_accuracy += tmp_eval_accuracy\n\n        # Track the number of batches\n        nb_eval_steps += 1\n\n    # Report the final accuracy for this validation run.\n    print(\"  FSCORE: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n\nprint(\"\")\nprint(\"Training complete!\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T12:38:42.842803Z","iopub.execute_input":"2021-12-21T12:38:42.843231Z","iopub.status.idle":"2021-12-21T14:14:46.188308Z","shell.execute_reply.started":"2021-12-21T12:38:42.843195Z","shell.execute_reply":"2021-12-21T14:14:46.187381Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 4 ========\nTraining...\n  Batch    40  of  3,344.    Elapsed: 0:00:17.\n  Batch    80  of  3,344.    Elapsed: 0:00:33.\n  Batch   120  of  3,344.    Elapsed: 0:00:50.\n  Batch   160  of  3,344.    Elapsed: 0:01:07.\n  Batch   200  of  3,344.    Elapsed: 0:01:23.\n  Batch   240  of  3,344.    Elapsed: 0:01:40.\n  Batch   280  of  3,344.    Elapsed: 0:01:57.\n  Batch   320  of  3,344.    Elapsed: 0:02:13.\n  Batch   360  of  3,344.    Elapsed: 0:02:30.\n  Batch   400  of  3,344.    Elapsed: 0:02:47.\n  Batch   440  of  3,344.    Elapsed: 0:03:03.\n  Batch   480  of  3,344.    Elapsed: 0:03:20.\n  Batch   520  of  3,344.    Elapsed: 0:03:37.\n  Batch   560  of  3,344.    Elapsed: 0:03:53.\n  Batch   600  of  3,344.    Elapsed: 0:04:10.\n  Batch   640  of  3,344.    Elapsed: 0:04:27.\n  Batch   680  of  3,344.    Elapsed: 0:04:43.\n  Batch   720  of  3,344.    Elapsed: 0:05:00.\n  Batch   760  of  3,344.    Elapsed: 0:05:17.\n  Batch   800  of  3,344.    Elapsed: 0:05:33.\n  Batch   840  of  3,344.    Elapsed: 0:05:50.\n  Batch   880  of  3,344.    Elapsed: 0:06:07.\n  Batch   920  of  3,344.    Elapsed: 0:06:23.\n  Batch   960  of  3,344.    Elapsed: 0:06:40.\n  Batch 1,000  of  3,344.    Elapsed: 0:06:57.\n  Batch 1,040  of  3,344.    Elapsed: 0:07:14.\n  Batch 1,080  of  3,344.    Elapsed: 0:07:30.\n  Batch 1,120  of  3,344.    Elapsed: 0:07:47.\n  Batch 1,160  of  3,344.    Elapsed: 0:08:04.\n  Batch 1,200  of  3,344.    Elapsed: 0:08:20.\n  Batch 1,240  of  3,344.    Elapsed: 0:08:37.\n  Batch 1,280  of  3,344.    Elapsed: 0:08:54.\n  Batch 1,320  of  3,344.    Elapsed: 0:09:10.\n  Batch 1,360  of  3,344.    Elapsed: 0:09:27.\n  Batch 1,400  of  3,344.    Elapsed: 0:09:43.\n  Batch 1,440  of  3,344.    Elapsed: 0:10:00.\n  Batch 1,480  of  3,344.    Elapsed: 0:10:17.\n  Batch 1,520  of  3,344.    Elapsed: 0:10:33.\n  Batch 1,560  of  3,344.    Elapsed: 0:10:50.\n  Batch 1,600  of  3,344.    Elapsed: 0:11:07.\n  Batch 1,640  of  3,344.    Elapsed: 0:11:23.\n  Batch 1,680  of  3,344.    Elapsed: 0:11:40.\n  Batch 1,720  of  3,344.    Elapsed: 0:11:57.\n  Batch 1,760  of  3,344.    Elapsed: 0:12:13.\n  Batch 1,800  of  3,344.    Elapsed: 0:12:30.\n  Batch 1,840  of  3,344.    Elapsed: 0:12:47.\n  Batch 1,880  of  3,344.    Elapsed: 0:13:03.\n  Batch 1,920  of  3,344.    Elapsed: 0:13:20.\n  Batch 1,960  of  3,344.    Elapsed: 0:13:37.\n  Batch 2,000  of  3,344.    Elapsed: 0:13:53.\n  Batch 2,040  of  3,344.    Elapsed: 0:14:10.\n  Batch 2,080  of  3,344.    Elapsed: 0:14:26.\n  Batch 2,120  of  3,344.    Elapsed: 0:14:43.\n  Batch 2,160  of  3,344.    Elapsed: 0:15:00.\n  Batch 2,200  of  3,344.    Elapsed: 0:15:16.\n  Batch 2,240  of  3,344.    Elapsed: 0:15:33.\n  Batch 2,280  of  3,344.    Elapsed: 0:15:50.\n  Batch 2,320  of  3,344.    Elapsed: 0:16:06.\n  Batch 2,360  of  3,344.    Elapsed: 0:16:23.\n  Batch 2,400  of  3,344.    Elapsed: 0:16:40.\n  Batch 2,440  of  3,344.    Elapsed: 0:16:56.\n  Batch 2,480  of  3,344.    Elapsed: 0:17:13.\n  Batch 2,520  of  3,344.    Elapsed: 0:17:30.\n  Batch 2,560  of  3,344.    Elapsed: 0:17:46.\n  Batch 2,600  of  3,344.    Elapsed: 0:18:03.\n  Batch 2,640  of  3,344.    Elapsed: 0:18:20.\n  Batch 2,680  of  3,344.    Elapsed: 0:18:36.\n  Batch 2,720  of  3,344.    Elapsed: 0:18:53.\n  Batch 2,760  of  3,344.    Elapsed: 0:19:10.\n  Batch 2,800  of  3,344.    Elapsed: 0:19:27.\n  Batch 2,840  of  3,344.    Elapsed: 0:19:43.\n  Batch 2,880  of  3,344.    Elapsed: 0:20:00.\n  Batch 2,920  of  3,344.    Elapsed: 0:20:17.\n  Batch 2,960  of  3,344.    Elapsed: 0:20:33.\n  Batch 3,000  of  3,344.    Elapsed: 0:20:50.\n  Batch 3,040  of  3,344.    Elapsed: 0:21:07.\n  Batch 3,080  of  3,344.    Elapsed: 0:21:23.\n  Batch 3,120  of  3,344.    Elapsed: 0:21:40.\n  Batch 3,160  of  3,344.    Elapsed: 0:21:57.\n  Batch 3,200  of  3,344.    Elapsed: 0:22:13.\n  Batch 3,240  of  3,344.    Elapsed: 0:22:30.\n  Batch 3,280  of  3,344.    Elapsed: 0:22:47.\n  Batch 3,320  of  3,344.    Elapsed: 0:23:03.\n\n  Average training loss: 0.54\n  Training epcoh took: 0:23:13\n\nRunning Validation...\n  FSCORE: 0.85\n  Validation took: 0:00:48\n\n======== Epoch 2 / 4 ========\nTraining...\n  Batch    40  of  3,344.    Elapsed: 0:00:17.\n  Batch    80  of  3,344.    Elapsed: 0:00:33.\n  Batch   120  of  3,344.    Elapsed: 0:00:50.\n  Batch   160  of  3,344.    Elapsed: 0:01:07.\n  Batch   200  of  3,344.    Elapsed: 0:01:23.\n  Batch   240  of  3,344.    Elapsed: 0:01:40.\n  Batch   280  of  3,344.    Elapsed: 0:01:57.\n  Batch   320  of  3,344.    Elapsed: 0:02:13.\n  Batch   360  of  3,344.    Elapsed: 0:02:30.\n  Batch   400  of  3,344.    Elapsed: 0:02:47.\n  Batch   440  of  3,344.    Elapsed: 0:03:04.\n  Batch   480  of  3,344.    Elapsed: 0:03:20.\n  Batch   520  of  3,344.    Elapsed: 0:03:37.\n  Batch   560  of  3,344.    Elapsed: 0:03:54.\n  Batch   600  of  3,344.    Elapsed: 0:04:10.\n  Batch   640  of  3,344.    Elapsed: 0:04:27.\n  Batch   680  of  3,344.    Elapsed: 0:04:44.\n  Batch   720  of  3,344.    Elapsed: 0:05:00.\n  Batch   760  of  3,344.    Elapsed: 0:05:17.\n  Batch   800  of  3,344.    Elapsed: 0:05:34.\n  Batch   840  of  3,344.    Elapsed: 0:05:50.\n  Batch   880  of  3,344.    Elapsed: 0:06:07.\n  Batch   920  of  3,344.    Elapsed: 0:06:23.\n  Batch   960  of  3,344.    Elapsed: 0:06:40.\n  Batch 1,000  of  3,344.    Elapsed: 0:06:57.\n  Batch 1,040  of  3,344.    Elapsed: 0:07:13.\n  Batch 1,080  of  3,344.    Elapsed: 0:07:30.\n  Batch 1,120  of  3,344.    Elapsed: 0:07:47.\n  Batch 1,160  of  3,344.    Elapsed: 0:08:03.\n  Batch 1,200  of  3,344.    Elapsed: 0:08:20.\n  Batch 1,240  of  3,344.    Elapsed: 0:08:37.\n  Batch 1,280  of  3,344.    Elapsed: 0:08:53.\n  Batch 1,320  of  3,344.    Elapsed: 0:09:10.\n  Batch 1,360  of  3,344.    Elapsed: 0:09:27.\n  Batch 1,400  of  3,344.    Elapsed: 0:09:43.\n  Batch 1,440  of  3,344.    Elapsed: 0:10:00.\n  Batch 1,480  of  3,344.    Elapsed: 0:10:16.\n  Batch 1,520  of  3,344.    Elapsed: 0:10:33.\n  Batch 1,560  of  3,344.    Elapsed: 0:10:50.\n  Batch 1,600  of  3,344.    Elapsed: 0:11:06.\n  Batch 1,640  of  3,344.    Elapsed: 0:11:23.\n  Batch 1,680  of  3,344.    Elapsed: 0:11:40.\n  Batch 1,720  of  3,344.    Elapsed: 0:11:56.\n  Batch 1,760  of  3,344.    Elapsed: 0:12:13.\n  Batch 1,800  of  3,344.    Elapsed: 0:12:30.\n  Batch 1,840  of  3,344.    Elapsed: 0:12:46.\n  Batch 1,880  of  3,344.    Elapsed: 0:13:03.\n  Batch 1,920  of  3,344.    Elapsed: 0:13:20.\n  Batch 1,960  of  3,344.    Elapsed: 0:13:36.\n  Batch 2,000  of  3,344.    Elapsed: 0:13:53.\n  Batch 2,040  of  3,344.    Elapsed: 0:14:10.\n  Batch 2,080  of  3,344.    Elapsed: 0:14:26.\n  Batch 2,120  of  3,344.    Elapsed: 0:14:43.\n  Batch 2,160  of  3,344.    Elapsed: 0:15:00.\n  Batch 2,200  of  3,344.    Elapsed: 0:15:16.\n  Batch 2,240  of  3,344.    Elapsed: 0:15:33.\n  Batch 2,280  of  3,344.    Elapsed: 0:15:50.\n  Batch 2,320  of  3,344.    Elapsed: 0:16:06.\n  Batch 2,360  of  3,344.    Elapsed: 0:16:23.\n  Batch 2,400  of  3,344.    Elapsed: 0:16:40.\n  Batch 2,440  of  3,344.    Elapsed: 0:16:56.\n  Batch 2,480  of  3,344.    Elapsed: 0:17:13.\n  Batch 2,520  of  3,344.    Elapsed: 0:17:30.\n  Batch 2,560  of  3,344.    Elapsed: 0:17:46.\n  Batch 2,600  of  3,344.    Elapsed: 0:18:03.\n  Batch 2,640  of  3,344.    Elapsed: 0:18:20.\n  Batch 2,680  of  3,344.    Elapsed: 0:18:36.\n  Batch 2,720  of  3,344.    Elapsed: 0:18:53.\n  Batch 2,760  of  3,344.    Elapsed: 0:19:10.\n  Batch 2,800  of  3,344.    Elapsed: 0:19:26.\n  Batch 2,840  of  3,344.    Elapsed: 0:19:43.\n  Batch 2,880  of  3,344.    Elapsed: 0:20:00.\n  Batch 2,920  of  3,344.    Elapsed: 0:20:16.\n  Batch 2,960  of  3,344.    Elapsed: 0:20:33.\n  Batch 3,000  of  3,344.    Elapsed: 0:20:50.\n  Batch 3,040  of  3,344.    Elapsed: 0:21:06.\n  Batch 3,080  of  3,344.    Elapsed: 0:21:23.\n  Batch 3,120  of  3,344.    Elapsed: 0:21:40.\n  Batch 3,160  of  3,344.    Elapsed: 0:21:56.\n  Batch 3,200  of  3,344.    Elapsed: 0:22:13.\n  Batch 3,240  of  3,344.    Elapsed: 0:22:30.\n  Batch 3,280  of  3,344.    Elapsed: 0:22:47.\n  Batch 3,320  of  3,344.    Elapsed: 0:23:03.\n\n  Average training loss: 0.39\n  Training epcoh took: 0:23:13\n\nRunning Validation...\n  FSCORE: 0.85\n  Validation took: 0:00:48\n\n======== Epoch 3 / 4 ========\nTraining...\n  Batch    40  of  3,344.    Elapsed: 0:00:17.\n  Batch    80  of  3,344.    Elapsed: 0:00:33.\n  Batch   120  of  3,344.    Elapsed: 0:00:50.\n  Batch   160  of  3,344.    Elapsed: 0:01:07.\n  Batch   200  of  3,344.    Elapsed: 0:01:23.\n  Batch   240  of  3,344.    Elapsed: 0:01:40.\n  Batch   280  of  3,344.    Elapsed: 0:01:57.\n  Batch   320  of  3,344.    Elapsed: 0:02:13.\n  Batch   360  of  3,344.    Elapsed: 0:02:30.\n  Batch   400  of  3,344.    Elapsed: 0:02:47.\n  Batch   440  of  3,344.    Elapsed: 0:03:03.\n  Batch   480  of  3,344.    Elapsed: 0:03:20.\n  Batch   520  of  3,344.    Elapsed: 0:03:37.\n  Batch   560  of  3,344.    Elapsed: 0:03:53.\n  Batch   600  of  3,344.    Elapsed: 0:04:10.\n  Batch   640  of  3,344.    Elapsed: 0:04:27.\n  Batch   680  of  3,344.    Elapsed: 0:04:43.\n  Batch   720  of  3,344.    Elapsed: 0:05:00.\n  Batch   760  of  3,344.    Elapsed: 0:05:16.\n  Batch   800  of  3,344.    Elapsed: 0:05:33.\n  Batch   840  of  3,344.    Elapsed: 0:05:50.\n  Batch   880  of  3,344.    Elapsed: 0:06:06.\n  Batch   920  of  3,344.    Elapsed: 0:06:23.\n  Batch   960  of  3,344.    Elapsed: 0:06:40.\n  Batch 1,000  of  3,344.    Elapsed: 0:06:56.\n  Batch 1,040  of  3,344.    Elapsed: 0:07:13.\n  Batch 1,080  of  3,344.    Elapsed: 0:07:30.\n  Batch 1,120  of  3,344.    Elapsed: 0:07:46.\n  Batch 1,160  of  3,344.    Elapsed: 0:08:03.\n  Batch 1,200  of  3,344.    Elapsed: 0:08:20.\n  Batch 1,240  of  3,344.    Elapsed: 0:08:36.\n  Batch 1,280  of  3,344.    Elapsed: 0:08:53.\n  Batch 1,320  of  3,344.    Elapsed: 0:09:09.\n  Batch 1,360  of  3,344.    Elapsed: 0:09:26.\n  Batch 1,400  of  3,344.    Elapsed: 0:09:43.\n  Batch 1,440  of  3,344.    Elapsed: 0:09:59.\n  Batch 1,480  of  3,344.    Elapsed: 0:10:16.\n  Batch 1,520  of  3,344.    Elapsed: 0:10:33.\n  Batch 1,560  of  3,344.    Elapsed: 0:10:49.\n  Batch 1,600  of  3,344.    Elapsed: 0:11:06.\n  Batch 1,640  of  3,344.    Elapsed: 0:11:23.\n  Batch 1,680  of  3,344.    Elapsed: 0:11:39.\n  Batch 1,720  of  3,344.    Elapsed: 0:11:56.\n  Batch 1,760  of  3,344.    Elapsed: 0:12:13.\n  Batch 1,800  of  3,344.    Elapsed: 0:12:29.\n  Batch 1,840  of  3,344.    Elapsed: 0:12:46.\n  Batch 1,880  of  3,344.    Elapsed: 0:13:03.\n  Batch 1,920  of  3,344.    Elapsed: 0:13:19.\n  Batch 1,960  of  3,344.    Elapsed: 0:13:36.\n  Batch 2,000  of  3,344.    Elapsed: 0:13:53.\n  Batch 2,040  of  3,344.    Elapsed: 0:14:09.\n  Batch 2,080  of  3,344.    Elapsed: 0:14:26.\n  Batch 2,120  of  3,344.    Elapsed: 0:14:43.\n  Batch 2,160  of  3,344.    Elapsed: 0:14:59.\n  Batch 2,200  of  3,344.    Elapsed: 0:15:16.\n  Batch 2,240  of  3,344.    Elapsed: 0:15:33.\n  Batch 2,280  of  3,344.    Elapsed: 0:15:49.\n  Batch 2,320  of  3,344.    Elapsed: 0:16:06.\n  Batch 2,360  of  3,344.    Elapsed: 0:16:23.\n  Batch 2,400  of  3,344.    Elapsed: 0:16:39.\n  Batch 2,440  of  3,344.    Elapsed: 0:16:56.\n  Batch 2,480  of  3,344.    Elapsed: 0:17:13.\n  Batch 2,520  of  3,344.    Elapsed: 0:17:29.\n  Batch 2,560  of  3,344.    Elapsed: 0:17:46.\n  Batch 2,600  of  3,344.    Elapsed: 0:18:03.\n  Batch 2,640  of  3,344.    Elapsed: 0:18:19.\n  Batch 2,680  of  3,344.    Elapsed: 0:18:36.\n  Batch 2,720  of  3,344.    Elapsed: 0:18:53.\n  Batch 2,760  of  3,344.    Elapsed: 0:19:09.\n  Batch 2,800  of  3,344.    Elapsed: 0:19:26.\n  Batch 2,840  of  3,344.    Elapsed: 0:19:43.\n  Batch 2,880  of  3,344.    Elapsed: 0:19:59.\n  Batch 2,920  of  3,344.    Elapsed: 0:20:16.\n  Batch 2,960  of  3,344.    Elapsed: 0:20:33.\n  Batch 3,000  of  3,344.    Elapsed: 0:20:49.\n  Batch 3,040  of  3,344.    Elapsed: 0:21:06.\n  Batch 3,080  of  3,344.    Elapsed: 0:21:23.\n  Batch 3,120  of  3,344.    Elapsed: 0:21:39.\n  Batch 3,160  of  3,344.    Elapsed: 0:21:56.\n  Batch 3,200  of  3,344.    Elapsed: 0:22:13.\n  Batch 3,240  of  3,344.    Elapsed: 0:22:29.\n  Batch 3,280  of  3,344.    Elapsed: 0:22:46.\n  Batch 3,320  of  3,344.    Elapsed: 0:23:02.\n\n  Average training loss: 0.32\n  Training epcoh took: 0:23:12\n\nRunning Validation...\n  FSCORE: 0.85\n  Validation took: 0:00:48\n\n======== Epoch 4 / 4 ========\nTraining...\n  Batch    40  of  3,344.    Elapsed: 0:00:17.\n  Batch    80  of  3,344.    Elapsed: 0:00:33.\n  Batch   120  of  3,344.    Elapsed: 0:00:50.\n  Batch   160  of  3,344.    Elapsed: 0:01:07.\n  Batch   200  of  3,344.    Elapsed: 0:01:23.\n  Batch   240  of  3,344.    Elapsed: 0:01:40.\n  Batch   280  of  3,344.    Elapsed: 0:01:56.\n  Batch   320  of  3,344.    Elapsed: 0:02:13.\n  Batch   360  of  3,344.    Elapsed: 0:02:30.\n  Batch   400  of  3,344.    Elapsed: 0:02:46.\n  Batch   440  of  3,344.    Elapsed: 0:03:03.\n  Batch   480  of  3,344.    Elapsed: 0:03:20.\n  Batch   520  of  3,344.    Elapsed: 0:03:36.\n  Batch   560  of  3,344.    Elapsed: 0:03:53.\n  Batch   600  of  3,344.    Elapsed: 0:04:10.\n  Batch   640  of  3,344.    Elapsed: 0:04:26.\n  Batch   680  of  3,344.    Elapsed: 0:04:43.\n  Batch   720  of  3,344.    Elapsed: 0:04:59.\n  Batch   760  of  3,344.    Elapsed: 0:05:16.\n  Batch   800  of  3,344.    Elapsed: 0:05:33.\n  Batch   840  of  3,344.    Elapsed: 0:05:49.\n  Batch   880  of  3,344.    Elapsed: 0:06:06.\n  Batch   920  of  3,344.    Elapsed: 0:06:23.\n  Batch   960  of  3,344.    Elapsed: 0:06:39.\n  Batch 1,000  of  3,344.    Elapsed: 0:06:56.\n  Batch 1,040  of  3,344.    Elapsed: 0:07:13.\n  Batch 1,080  of  3,344.    Elapsed: 0:07:29.\n  Batch 1,120  of  3,344.    Elapsed: 0:07:46.\n  Batch 1,160  of  3,344.    Elapsed: 0:08:03.\n  Batch 1,200  of  3,344.    Elapsed: 0:08:19.\n  Batch 1,240  of  3,344.    Elapsed: 0:08:36.\n  Batch 1,280  of  3,344.    Elapsed: 0:08:53.\n  Batch 1,320  of  3,344.    Elapsed: 0:09:09.\n  Batch 1,360  of  3,344.    Elapsed: 0:09:26.\n  Batch 1,400  of  3,344.    Elapsed: 0:09:43.\n  Batch 1,440  of  3,344.    Elapsed: 0:09:59.\n  Batch 1,480  of  3,344.    Elapsed: 0:10:16.\n  Batch 1,520  of  3,344.    Elapsed: 0:10:32.\n  Batch 1,560  of  3,344.    Elapsed: 0:10:49.\n  Batch 1,600  of  3,344.    Elapsed: 0:11:06.\n  Batch 1,640  of  3,344.    Elapsed: 0:11:22.\n  Batch 1,680  of  3,344.    Elapsed: 0:11:39.\n  Batch 1,720  of  3,344.    Elapsed: 0:11:56.\n  Batch 1,760  of  3,344.    Elapsed: 0:12:12.\n  Batch 1,800  of  3,344.    Elapsed: 0:12:29.\n  Batch 1,840  of  3,344.    Elapsed: 0:12:46.\n  Batch 1,880  of  3,344.    Elapsed: 0:13:02.\n  Batch 1,920  of  3,344.    Elapsed: 0:13:19.\n  Batch 1,960  of  3,344.    Elapsed: 0:13:36.\n  Batch 2,000  of  3,344.    Elapsed: 0:13:52.\n  Batch 2,040  of  3,344.    Elapsed: 0:14:09.\n  Batch 2,080  of  3,344.    Elapsed: 0:14:26.\n  Batch 2,120  of  3,344.    Elapsed: 0:14:42.\n  Batch 2,160  of  3,344.    Elapsed: 0:14:59.\n  Batch 2,200  of  3,344.    Elapsed: 0:15:16.\n  Batch 2,240  of  3,344.    Elapsed: 0:15:32.\n  Batch 2,280  of  3,344.    Elapsed: 0:15:49.\n  Batch 2,320  of  3,344.    Elapsed: 0:16:06.\n  Batch 2,360  of  3,344.    Elapsed: 0:16:22.\n  Batch 2,400  of  3,344.    Elapsed: 0:16:39.\n  Batch 2,440  of  3,344.    Elapsed: 0:16:56.\n  Batch 2,480  of  3,344.    Elapsed: 0:17:12.\n  Batch 2,520  of  3,344.    Elapsed: 0:17:29.\n  Batch 2,560  of  3,344.    Elapsed: 0:17:46.\n  Batch 2,600  of  3,344.    Elapsed: 0:18:02.\n  Batch 2,640  of  3,344.    Elapsed: 0:18:19.\n  Batch 2,680  of  3,344.    Elapsed: 0:18:35.\n  Batch 2,720  of  3,344.    Elapsed: 0:18:52.\n  Batch 2,760  of  3,344.    Elapsed: 0:19:09.\n  Batch 2,800  of  3,344.    Elapsed: 0:19:25.\n  Batch 2,840  of  3,344.    Elapsed: 0:19:42.\n  Batch 2,880  of  3,344.    Elapsed: 0:19:59.\n  Batch 2,920  of  3,344.    Elapsed: 0:20:15.\n  Batch 2,960  of  3,344.    Elapsed: 0:20:32.\n  Batch 3,000  of  3,344.    Elapsed: 0:20:48.\n  Batch 3,040  of  3,344.    Elapsed: 0:21:05.\n  Batch 3,080  of  3,344.    Elapsed: 0:21:22.\n  Batch 3,120  of  3,344.    Elapsed: 0:21:38.\n  Batch 3,160  of  3,344.    Elapsed: 0:21:55.\n  Batch 3,200  of  3,344.    Elapsed: 0:22:12.\n  Batch 3,240  of  3,344.    Elapsed: 0:22:28.\n  Batch 3,280  of  3,344.    Elapsed: 0:22:45.\n  Batch 3,320  of  3,344.    Elapsed: 0:23:02.\n\n  Average training loss: 0.27\n  Training epcoh took: 0:23:11\n\nRunning Validation...\n  FSCORE: 0.85\n  Validation took: 0:00:48\n\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}